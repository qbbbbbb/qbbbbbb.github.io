<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>内存重排序</title>
    <link href="/2023/11/01/%E5%86%85%E5%AD%98%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <url>/2023/11/01/%E5%86%85%E5%AD%98%E9%87%8D%E6%8E%92%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/125737864"class="uri">https://zhuanlan.zhihu.com/p/125737864</a></li></ul></li></ul><hr /><h2 id="内存重排序">1. 内存重排序</h2><ul><li><ahref="https://www.cnblogs.com/qianbinbin/p/17731460.html">这篇博客</a>中介绍由于对MESI的优化导致出现重排序，这里主要介绍内存重排序。</li><li>这里只考虑一个核重排序两个不同内存地址的内存操作（load/store）；对于相同地址的内存操作，在顺序执行（冯诺依曼）架构下要求是按照程序顺序执行。</li><li>根据内存操作是load/store，重排序可以分为下面三种场景<ul><li>store - store<ul><li>由于MESI优化时，为每个CPU插入了一个storebuffer，可能会出现有的store操作需要写数据到storebuffer，而有的store操作不需要写入storebuffer；从而导致两个store操作可能会发生重排序。具体可以看MESI协议相关内容的<ahref="https://www.cnblogs.com/qianbinbin/p/17731460.html">博客</a>。</li></ul></li><li>load - load<ul><li>考虑到读出时，有的可以直接从storebuffer/cache中读出，而有的则需要先从内存中取数据并与其它CPU进行比较再读出；从而导致了load-load重排序。</li></ul></li><li>store - load &amp; load - store<ul><li>和上面的介绍相同，由于读出/写入cache状态不同，导致有不一样的延时，可能会发生store - load / load -store重排序。</li></ul></li></ul></li><li>对于x86架构处理器，为TSO内存一致性模型，仅支持store -load重排序，其它三种均不支持。具体内容见<ahref="https://www.cnblogs.com/qianbinbin/p/17723730.html">这篇博客</a>。</li></ul><h2 id="内存屏障">2. 内存屏障</h2><ul><li>为了禁止部分类型的内存重排序，可以通过插入内存屏障(MemoryBarriers)。</li><li>下面对两种类型的内存屏障分析基于以下代码。 <figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-comment">//CPU0执行func1()，CPU1执行func2()，a变量在CPU1的cache中，b变量在CPU0的cache中。</span><br>a=<span class="hljs-number">0</span>,b=<span class="hljs-number">0</span>;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">func1</span>()</span>&#123;<br>  a=<span class="hljs-number">1</span>;<br>  smp_mb();<br>  b=<span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">fun2</span>()</span>&#123;<br>  <span class="hljs-keyword">while</span>(b==<span class="hljs-number">0</span>) <span class="hljs-keyword">continue</span>;<br>  smp_mb();<br>  assert(a=<span class="hljs-number">1</span>);<br>&#125;<br></code></pre></td></tr></table></figure></li><li>上面代码执行过程如下<ul><li>（1）CPU0执行a=1的赋值操作，由于a不在CPU0的cache中，所以CPU0先将写入值1放在storebuffer中，并发送invalid message到总线上。</li><li>（2）CPU1执行while(b==0)循环判断，由于b不在CPU1的cache里面，所以CPU1发送一个readmessage到总线上，观察其它CPU是否有此地址的cache以及memory中是否有相关信息。</li><li>（3）CPU1 收到CPU0的invalid信息后，立即返回已经invalid信息，并将invalid信息送入invalidqueue，在CPU空闲时清空自己的cacheline。</li><li>（4）CPU0 收到CPU1的invalid回执后，将storebuffer中的值<strong>a=1</strong>写回cacheline中，并更改状态为modified。</li><li>（5）CPU1收到CPU0发送的b值，并将其写入自己的cache中，并将状态设为shared状态。</li><li>（6）CPU1 将b的值从cacheline中load到寄存器中，此时满足条件b==0，所以一直在循环。</li><li>（7）CPU0 执行smp_mb()函数，应该将storebuffer中的数据都写入cache中，就这个例子，a=1已经写入cache中了。</li><li>（8）CPU0执行b=1的赋值操作，由于b的值在CPU0的cache中，原状态为shared，所以需要发送invalid信号给其它CPU，先写入storebuffer中。</li><li>（9）CPU0 在接收到CPU1的invalid回执后，将b=1值写入cache中，并更改状态为modified。而CPU1对应地址的cache应为invalid。</li><li>（10）CPU1 再次发现b所在cache为invalid状态，所以CPU1发送一个readmessage到总线上，观察其它CPU是否有此地址的cache以及memory中是否有相关信息。</li><li>（11）CPU1收到CPU0发送的b值，并将其写入自己的cache中，并将状态设为Modified状态。</li><li>（12）CPU1 将b的值从cacheline中load到寄存器中，此时不满足条件b==0，所以跳出循环。</li><li>（13）CPU1 执行smp_mb()函数，会对invalidqueue中的项进行标注，随后相关cacheline的load操作需要等待invalidqueue中被处理，才可以继续执行。</li><li>（14）CPU1在smp_mb()函数之后，a相关的cache被清除，需要重新读取。如果没有该处屏障，那么CPU1会拿到a最原始的值0，assert失败。</li><li>（15）CPU1发送一个readmessage到总线上，观察其它CPU是否有此地址的cache以及memory中是否有相关信息。最终从CPU0那里获取到a=1的新值，assert正确。</li></ul></li><li>上面介绍的过程中，smp_mb()函数主要包括两类：<ul><li>Store Memory Barriers<ul><li>告诉CPU在执行 屏障之后的指令 前，需要先将所有在storebuffer中的数据更新到cacheline中。</li></ul></li><li>Load Memory Barriers<ul><li>告诉CPU在执行任何load操作前，先处理所有在invalid queue中的invalid消息。</li></ul></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MESI协议</title>
    <link href="/2023/11/01/MESI%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/11/01/MESI%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/375706879"class="uri">https://zhuanlan.zhihu.com/p/375706879</a></li><li><a href="https://zhuanlan.zhihu.com/p/112605471"class="uri">https://zhuanlan.zhihu.com/p/112605471</a></li><li><a href="https://zhuanlan.zhihu.com/p/125549632"class="uri">https://zhuanlan.zhihu.com/p/125549632</a></li></ul></li></ul><hr /><h2 id="mesi-四种状态">1. MESI 四种状态</h2><ul><li>在<ahref="https://www.cnblogs.com/qianbinbin/p/17617970.html">这篇博客</a>中有介绍MESI协议的四种状态分别为：Modified、Exclusive、Shared、Invalid.</li><li>由于下面四种操作，Cache的状态会在MESI间跳转。<ul><li>LR: Local Read，当前CPU读操作</li><li>LW: Local Write，当前CPU写操作</li><li>RR：Remote Read，其它CPU读操作</li><li>RW: Remote Write，其它CPU写操作</li></ul></li></ul><p><img src="3201119-20230926232206330-164782807.png" style="zoom:50%;" /></p><ul><li>针对上面的状态转移图，进行下面四种状态的详细分析。<ul><li>Modified<ul><li>LR：当前CPU读操作，缓存中拥有最新数据，直接从缓存中读取就可以。仍为<strong>Modified</strong>。</li><li>LW：当前CPU写操作，直接修改当前CPU缓存数据，修改后仍拥有最新数据，仍为<strong>Modified</strong>。</li><li>RR：其它CPU读操作，为了保证一致性，需要当前CPU将数据写回内存，并从当前CPU中获取cacheline给到其它CPU，并更改所有CPU状态为<strong>Shared</strong>。<br /></li><li>RW：其它CPU写操作，需要当前CPU将数据写回内存，并完成其它CPU的写操作，以及更改除完成写的CPU 的其它CPU状态为<strong>Invalid</strong>。</li></ul></li><li>Exclusive<ul><li>LR：当前CPU读操作，可以直接读出，仍为<strong>Exclusive</strong>。</li><li>LW：当前CPU写操作，修改当前缓存内的数据，并更改状态为<strong>Modified</strong>。</li><li>RR：其它CPU读操作，将当前CPUcache中的数据分享给其它CPU，并更改状态为<strong>Shared</strong>。</li><li>RW：其它CPU写操作，当前CPU的Cacheline不可用，更改当前状态为<strong>Invalid</strong>。</li></ul></li><li>Shared<ul><li>LR：当前CPU读操作，可以直接读出，仍为<strong>shared</strong>。</li><li>LW：当前CPU写操作，更改状态为<strong>Modified</strong>。</li><li>RR：其它CPU读操作，多个CPU的数据都与内存中一致，所以状态仍为<strong>Shared</strong>。</li><li>RW：其它CPU写操作，其它CPU数据为最新，当前CPU数据失效，更改当前CPU状态为<strong>Invalid</strong>。</li></ul></li><li>Invalid<ul><li>LR：当前CPU读操作，CPU缓存不可用，需要重新从内存中加载cacheline。<ul><li>其它CPU无数据，当前CPU加载新的数据后，更改状态为<strong>Exclusive</strong>。</li><li>其它CPU有数据，且状态为S/E，即从内存中取出数据与其它CPU数据一致，那么状态修改为<strong>Shared</strong>。</li><li>其它CPU有数据，且状态为M，即其cache中数据和内存中数据不一致，那么会先让其它CPU将数据写回内存中，随后当前CPU再读出内存中数据，此时当前CPU的数据和其它CPU以及内存中数据均一致，状态修改为<strong>Shared</strong>。</li></ul></li><li>LW：当前CPU写操作，当前CPU缓存不可用，首先需要从内存中取出数据到cacheline。<ul><li>其它CPU无数据，且当前CPU写入数据和内存数据不一致时，更改状态为<strong>Modified</strong>。</li><li>其它CPU有数据，且它们状态为S/E，那么当前CPU写入数据，并更新当前CPU状态为<strong>Modified</strong>。</li><li>其它CPU有数据，且它们状态为M，那么需要先将其它CPU的cache数据写回主存，随后再写入当前CPU的cache中，并更新状态为<strong>Modified</strong>。并发送给其它CPUinvalid信号。</li></ul></li><li>RR：其它CPU读操作，因为当前CPU处于Invalid状态，所以其它CPU读操作与当前CPU无关，状态保持<strong>Invalid</strong>。</li><li>RW：其它CPU写操作，因为当前CPU处于Invalid状态，所以其它CPU写操作与当前CPU无关，状态保持<strong>Invalid</strong>。</li></ul></li></ul></li></ul><h2 id="mesi-协议的问题及优化">2. MESI 协议的问题及优化</h2><ul><li>问题<ul><li>考虑到在MESI中，需要依赖总线嗅探机制，整个过程是串行的，因此可能会发生阻塞。举例如下。<ul><li>假设CPU0 特定地址的cacheline为shared状态，那么CPU0会发送invalid信号给其它CPU。</li><li>而其它CPU接收到invalid信号后，将对应cacheline的valid bit拉低。</li><li>CPU0 会在收到CPU1更改invalid信息后，再修改对应cacheline的数据，并将对应的状态更改为Modified。所以存在一段阻塞时间。</li><li>另外当高速缓存压力很大时，可能实时处理invalid事件也需要一定阻塞时间。两种阻塞情况都会导致性能降低。</li></ul></li></ul></li><li>优化<ul><li>Store Buffer<ul><li>可为每个CPU添加一个Store Buffer。<ul><li>当发生LW时，CPU可以不用等待其它CPU回复的信息，直接将更新的值写入StoreBuffer中，继续执行后续操作，不必插入阻塞等待时间。<ul><li>在其它CPU回复后，再将数据从Store Buffer中写入cacheline，并更改状态为Modified。</li></ul></li></ul></li><li>当发生LR时，CPU可以先在Store Buffer中查找，如果存在直接从StoreBuffer中获取，若没有再查找Cache Line。</li></ul></li><li>Invalid Queue<ul><li>为什么需要invalid queue<ul><li>假设所有的store操作都需要CPU发出invalid信号给其它CPU，storebuffer可能会被填满，那么CPU只能进入等待状态。性能并没有得到很大提升。</li><li>引入invalid queue可以加快收到invalid回执的速度，减少每个数据在storebuffer停留时间段。</li></ul></li><li>可为每个CPU添加一个Invalid Queue。<ul><li>当发生RW操作时，当前CPU都需要进行Invalid操作，并返回给那个正在完成LW操作的CPU信息。</li><li>使用失效队列后，当前CPU会首先将接收到的Invalid信息放到InvalidQueue中，并立即返回已经invalid的信息。在后续CPU空闲下来时再处理InvalidQueue中的信息，将对应地址的cache line置为无效。</li></ul></li><li>如果当前CPU想要发送MESI信息给其它CPU，会先检查invalidqueue中是否有相关的cacheline，如果有的话，那么不可以立刻发送，需要等待invalidqueue中的cacheline被处理之后再发送。</li></ul></li></ul></li><li>优化后的问题<ul><li>插入 Store Buffer之后，可能会出现即使指令本身是按照顺序执行的，但最终仍然会<strong>乱序执行</strong>。<ul><li>举例1：按照顺序依次执行A,B两个写指令，A写指令对应地址缓存处于S状态，B写指令对应地址缓存处于E状态，那么B会比A先完成写入操作。<ul><li>因为A写入之后，需要发送给其它CPU invalid信息，A写入的数据会进入StoreBuffer中；而B写入之后，由于cacheline是独占的，所以不需要通知其它CPU，直接更改cacheline中的数据就可以，并更新状态为Modified。<br /></li></ul></li><li>举例2：按照顺序依次执行C,D两个读指令，C读指令对应地址缓存处于I状态，D读指令对应地址缓存处于S状态，那么D会比C先完成读操作。<ul><li>因为C读取前，需要先从内存中加载cacheline，并需要与其它CPU进行比较，参考上面Invalid的介绍。而D读取可以直接读出，并不需要更改状态。</li></ul></li></ul></li><li>插入 Invalid Queue 之后，可能会导致读取到过时的数据。<ul><li>举例：CPU0执行LW操作，对应cacheline为S状态，那么他会发送invalid信息给其它CPU，CPU1会将invalid信息写入他的invalidqueue，并立即回复CPU0表示已经执行invalid操作（后面都会称这个过程为返回回执）。<ul><li>CPU0接收到回执后，更新缓存行，但是CPU1可能还没来得及做invalid操作，此时CPU1如果发生读操作，会导致读到过时数据。</li></ul></li></ul></li></ul></li></ul><h2 id="重排序">3. 重排序</h2><ul><li>前面有介绍优化MESI后可能会出现的一致性问题。MESI协议原是强一致性，为了优化其性能，最终弱化成了最终一致性。可能会出现重排序的情况。</li><li>重排序一般包括下面三种<ul><li>编译器优化的重排序<ul><li>编译器在不改变单线程语义的前提下，可以重新安排语句的执行顺序。</li></ul></li><li>指令级并行的重排序<ul><li>处理器采用指令级并行技术（Instruction-LevelParallesim，ILP），如果指令之间不存在数据依赖性，处理器可以改变语句对应的机器指令的执行顺序。</li><li>ILP相关内容可以看<ahref="https://www.cnblogs.com/qianbinbin/p/17735751.html">这篇博客</a>。</li></ul></li><li>内存系统的重排序<ul><li>由于处理器使用缓存和读/写缓冲区，使得load和store看上去是乱序执行的。</li><li>内存重排序相关内容可以看<ahref="https://www.cnblogs.com/qianbinbin/p/17738130.html">这篇博客</a>。</li></ul></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>内存模型</title>
    <link href="/2023/11/01/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
    <url>/2023/11/01/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><ahref="https://blog.csdn.net/weixin_43008591/article/details/131872164"class="uri">https://blog.csdn.net/weixin_43008591/article/details/131872164</a></li><li><a href="https://zhuanlan.zhihu.com/p/422848235"class="uri">https://zhuanlan.zhihu.com/p/422848235</a></li><li><ahref="https://blog.csdn.net/qq_29328443/article/details/107616795"class="uri">https://blog.csdn.net/qq_29328443/article/details/107616795</a></li><li><a href="https://zhuanlan.zhihu.com/p/563126470"class="uri">https://zhuanlan.zhihu.com/p/563126470</a></li><li><a href="https://zhuanlan.zhihu.com/p/563127372"class="uri">https://zhuanlan.zhihu.com/p/563127372</a></li><li><ahref="https://blog.csdn.net/qq_29328443/article/details/104215898"class="uri">https://blog.csdn.net/qq_29328443/article/details/104215898</a></li><li><ahref="https://gitee.com/laokz/OS-kernel-test/blob/master/memorder/riscv.md"class="uri">https://gitee.com/laokz/OS-kernel-test/blob/master/memorder/riscv.md</a></li><li><ahref="https://drive.google.com/file/d/1s0lZxUZaa7eV_O0_WsZzaurFLLww7ou5/view"class="uri">https://drive.google.com/file/d/1s0lZxUZaa7eV_O0_WsZzaurFLLww7ou5/view</a></li><li><a href="https://zhuanlan.zhihu.com/p/21387258"class="uri">https://zhuanlan.zhihu.com/p/21387258</a></li><li>《A Primer on Memory Consistency and Cache Coherence》</li></ul></li></ul><hr /><h2 id="写在前面">0. 写在前面</h2><ul><li>这部分知识的学习是兴趣导向，没有项目支撑，可能部分理解并不正确，欢迎一起讨论。</li></ul><h2 id="隐式-显式-内存访问">1. 隐式 &amp; 显式 内存访问</h2><ul><li>隐式：从存储器中取出指令的过程。</li><li>显式：加载/存储指令，根据指令的地址进行显式读写内存操作。</li></ul><h2 id="内存一致性模型">2. 内存一致性模型</h2><h3 id="共享内存-执行顺序问题">2.1 共享内存 执行顺序问题</h3><ul><li>举例如下，C1和C2执行顺序可以有多种组合，r1、r2的值也会有多种结果，如下表所示。</li></ul><p><img src="3201119-20230923112425619-324331088.png" style="zoom:50%;"/></p><ul><li>甚至对于一些系统，{r1,r2}={0,0}.而这些执行顺序是都满足cachecoherence。</li></ul><table><thead><tr class="header"><th>r1</th><th>r2</th><th>执行顺序</th></tr></thead><tbody><tr class="odd"><td>0</td><td>NEW</td><td>S1-L1-S2-L2</td></tr><tr class="even"><td>NEW</td><td>0</td><td>S2-L2-S1-L1</td></tr><tr class="odd"><td>NEW</td><td>NEW</td><td>S1-S2-L1-L2</td></tr></tbody></table><h3 id="sequential-consistensy">2.2 Sequential Consistensy</h3><h4 id="关于-sc">2.2.1 关于 SC</h4><ul><li>该模型要求<ul><li>所有的内存访问操作都是<strong>原子操作</strong>，即两个/多个核不能同时对内存进行操作。</li><li>对于<strong>单个核</strong>内的内存访问要求<strong>严格按照程序代码顺序</strong>执行（无论是指令顺序执行/乱序执行）。</li><li>对于多核间，程序代码可以任意顺序交织执行。</li></ul></li><li>举例如下<ul><li>图中(a)(b)(c)满足顺序一致性模型；(d)不满足顺序一致性模型，因为Core2的程序顺序(S2,L2)和内存顺序(L2,S2)不一致。</li></ul></li></ul><p><img src="3201119-20230923165655184-1696324924.png" style="zoom:50%;"/></p><p><img src="3201119-20230925142959738-1356371306.png" style="zoom:50%;"/></p><h4 id="sc-实现方法">2.2.2 SC 实现方法</h4><ul><li>简单的SC实现<ul><li><p>对于多任务的单核处理器：</p><ul><li>在单个核上执行所有线程，线程T1执行一段时间后，进行上下文切换，之后再开始执行T2。</li><li>在上下文切换时必须保证完成所有之前的内存访问指令，来保证SC的规则。</li></ul></li><li><p>使用 Switch模块 处理多核间的内存访问请求：</p><ul><li>前面介绍到SC模型是原子操作，所以内存模型提供的核和内存之间的抽象接口应该是下图的Switch开关模型。</li><li>每个核按照自己对应的<strong>程序顺序</strong>向Switch模块发起内存访问请求，Switch模块负责接收内存请求，并处理。</li></ul><p><img src="3201119-20231001153427562-684741947.png" style="zoom:50%;"/></p></li><li><p>这两种方法可以证明SC模型的可行性，但是随着核的数量增加，会很快遇到性能瓶颈。尤其Switch开关让人觉得SC模型无法并发执行，实际可对其进行优化，提升性能。</p></li></ul></li><li>有 Cache 一致性的基础SC实现<ul><li><p>增加cache，可以并行执行 不冲突的store和load操作。</p><ul><li>这里冲突的定义是，在同一时刻，两个操作同时访问一个地址，且其中至少一个操作是store。<br /></li></ul></li><li><p>如下图，每个核对应一个cache。<ahref="https://www.cnblogs.com/qianbinbin/p/17617970.html">这篇博客</a>中有介绍多核Cache间的一致性，可通过缓存一致性协议（MESI/MSI/MOESI等）保障。</p><p><img src="3201119-20231001170429491-2132919648.png" style="zoom:50%;"/></p><ul><li>这里假设使用的是MSI协议，那么可以通过cache的MSI状态，来设定当前的内存是否可读/写。<ul><li>Modified状态，表示当前<strong>内存</strong>可读可写。</li><li>Share状态，表示当前<strong>内存</strong>只可读。</li><li>注意：这里可读可写指的是内存，只有在M状态，会出现cacheline中的数据载入内存中。</li></ul></li></ul><p><img src="3201119-20231001212529763-371812296.png" style="zoom:50%;"/></p></li></ul></li><li>有 Cache 一致性的优化SC实现<ul><li>目前大部分内核的SC实现会在基础SC实现基础上加很多技术以提高性能，下面将详细介绍。</li><li>（1）Non-Binding Prefetching<ul><li>硬件预取相关内容可看<ahref="https://www.cnblogs.com/qianbinbin/p/17740391.html">这篇博客</a>。</li><li>可以通过硬件预取的方式，隐藏内存访问延迟，降低cache失效带来的延迟时间。</li><li>由于非绑定预取的预取值是放在cache/buffer中的，仍需满足cachecoherence。不会影响到内存模型。<br /></li></ul></li><li>（2）Speculative Cores</li><li>（3）Dynamically Scheduled Cores</li><li>（4）Non-Binding Prefetching in Dynamically Scheduled Cores</li><li>（5）Multithreading</li></ul></li></ul><h4 id="sc-内存模型下的原子操作">2.2.3 SC 内存模型下的原子操作</h4><ul><li>原子操作就是不可中断的一个或者一系列操作，不会被线程调度机制打断的操作。</li><li>实现原子操作并不难，但是过于简化的设计会导致性能不佳。<ul><li>例如，在原子操作开始时，让处理器锁定内存系统，防止其它内核进行内存访问，在完成原子操作（读/写）之后，再打开内存系统义工其它CPU访问。</li></ul></li><li>原子RMW操作<ul><li>RMW：如果CPU想要更改一个变量的值，那么发生的操作为：从内存<strong>读</strong>出对应地址的值放到寄存器中（read），然后修改寄存器中的值（modify），最后将修改后的值写回内存位置（write），这个过程称为RMW。</li><li>RMW的原子操作可以通过在缓存中实现，注意由于SC对内存操作顺序的严格要求，不存在storebuffer、invalid queue。<ul><li>在单个CPU的缓存中实现load和store操作，期间阻塞其它CPU发来的一致性请求信息，在原子操作完成之后再响应其它处理器即可。</li><li>前提条件：原子操作对应的cacheline状态为M（这里仍假设使用的是MSI协议，如上介绍只有M状态可读可写）。</li></ul></li><li>可以对上面的实现方式进行优化<ul><li>考虑到MSI协议中S状态也可读，所以可以实现在不违反原子性的情况下，允许load和store中间有其它操作。</li><li>举例：原子操作对应的cacheline状态为S，此时可以进行load操作，期间若当前CPU发生写操作，那么会更改状态为Modified，此时可以发生store操作。</li><li>但是上面这个过程并不一定能够保证原子性，即无法保证在load和store操作是否会有其它CPU发起一致性请求信息，导致当前CPU的cacheline状态被更改。所以需要处理器进行检查。</li></ul></li></ul></li></ul><h3 id="total-store-orderingtso">2.3 Total Store Ordering（TSO）</h3><h4 id="关于tso">2.3.1 关于TSO</h4><ul><li><p>为什么需要TSO</p><ul><li><p>举例1如下</p><p><img src="3201119-20231005200319206-1292757074.png" style="zoom:50%;"/></p><ul><li>在考虑存在storebuffer的情况下，那么两个处理器可以按照下面的顺序执行：<ul><li>（1）C1执行S1，将store的新值NEW放到store buffer中。</li><li>（2）C2执行S2，将store的新值NEW放到store buffer中。</li><li>（3）C1和C2分别执行内存load操作，此时load的值均为0。</li><li>（4）最后CPU将store buffer中的值写回内存中。</li><li>注意：CPU在load 内存值前，会先查看storebuffer，因此C1是可以看到x的值，但看不到y的值，所以r1=0；C2同理。</li></ul></li></ul></li><li><p>上面描述的执行违反了SC，使用storebuffer这类可提升性能的硬件设计，需要对内存操作进行重排序。</p><ul><li>对于SC模型，四种内存操作顺序组合中，四种都需满足，严格按照程序顺序向内存发起访问请求。</li><li>对于TSO模型，四种内存操作顺序组合中，仍需满足load-load/load-store/store-store这三个约束，仅支持store-load重排序操作。</li></ul></li></ul></li><li><p>举例2如下</p><ul><li>C1首先将x的新值NEW写入storebuffer中，同理，y的新值NEW也被放到C2的store buffer中。</li><li>C1、C2首先进行的内存操作是L1和L3，此时CPU查看到C1、C2的storebuffer中都有x和y的值，所以r1和r3的值分别为新值。</li><li>C1、C2之后进行的内存操作是L2和L4，此时C1和C2分别看到y和x的值为初始值，所以r2和r4的值均为0.</li><li>最后进行的内存操作是S1和S2，此时进行的是store-load重排序，满足TSO模型，将x和y的新值NEW写入内存中。</li></ul><p><img src="3201119-20231005204023094-1910416683.png" style="zoom:50%;"/></p><p><img src="3201119-20231005203938302-741663026.png" style="zoom:50%;"/></p></li></ul><h4 id="tso-实现方法">2.3.2 TSO 实现方法</h4><ul><li>与SC模型类似，可以使用Switch实现，或是带缓存一致性的内存模型实现。</li><li>与SC的区别在于添加了store buffer。<ul><li><p>该store buffer可以选择为每个CPU分别添加一个或是使用共享storebuffer，但buffer中每个条目由CPU id进行标记，需要对应的id相匹配。</p><p><img src="3201119-20231008130209670-1983742951.png" style="zoom:50%;"/></p></li></ul></li></ul><h4 id="tso-模型下的原子操作">2.3.3 TSO 模型下的原子操作</h4><ul><li>这里仍以RMW原子操作为例：<ul><li>考虑到store操作需要CPU从storebuffer中取值写入内存，由于TSO模型支持Store-Load重排序，那么可能会发生下图情况，其中S1为之前的store操作，此时难以保证RMW的原子操作。</li><li>因此，原子RMW操作应在清空store buffer之后再执行。<ul><li><p>这里清空store buffer的意思是指将storebuffer中所有的值都写回内存中。</p></li><li><p>为了保证load之后可以马上进行store操作，需要在load时保证对应cacheline状态为M状态（可读可写状态）。</p><ul><li>由于此时cacheline的状态为Modified状态，所以store操作可以直接写入cache中，绕过storebuffer。</li></ul></li><li><p>并且在load和store之间不能处理缓存一致性相关信息，在完成store操作之后再处理。</p><p><img src="3201119-20231005232829753-1126412102.png" style="zoom:50%;"/></p></li></ul></li></ul></li></ul><h4 id="fence-指令">2.3.4 FENCE 指令</h4><ul><li>在TSO下，store-load可以发生重排序，当程序员希望store-load之间为定序，那么可以通过插入FENCE指令来实现。<ul><li><p>如下表，由于C1和C2都在S和L操作之间插入了FENCE指令，所以在FENCE时，需要将storebuffer中所有的值都写回cache中。因此最后的结果不可能是{r1,r2}={0,0}.</p><p><img src="3201119-20231006141541627-33100539.png" style="zoom:50%;"/></p></li></ul></li><li>在<ahref="https://www.cnblogs.com/qianbinbin/p/17738130.html">这篇博客</a>中，有介绍可通过内存屏障来保证一些内存操作的顺序，其中使用的函数smp_mb()是封装在linux操作系统层的。<ul><li>RISC-V的指令集架构中是提供了Fence指令来做内存访问的同步。</li></ul></li></ul><h3 id="relaxed-consistensy">2.4 Relaxed Consistensy</h3><h4 id="关于-rmorelax-memory-order">2.4.1 关于 RMO（Relax MemoryOrder）</h4><ul><li>为什么需要RMO<ul><li>一些情景下，内存操作顺序即使发生重排序也不会影响最终语义，此时可以放松内存模型限制来提升性能。</li><li>RMO下需要程序员根据内存操作之间的数据依赖关系考虑 添加内存屏障等操作来保证顺序。</li></ul></li></ul><h4 id="rmo-下提升性能的优化方法">2.4.2 RMO 下提升性能的优化方法</h4><ul><li>（1）Non-FIFO, Coalescing Write Buffer<ul><li>在TSO中，我们要求StoreBuffer必须是基于FIFO实现的。因此写入buffer的数据顺序就是刷入cache中的顺序。</li><li>在RMO中，Store Buffer的设计 允许 来自<strong>一个 cacheline</strong>的相近几个写请求被合并到一个store buffer表项中。<ul><li>storebuffer的合并写入也需要特定的要求限制，具体分析可以学习ARM架构下StoreBuffer的设计。具体可见<ahref="https://cnblogs.com/vaughnhuang/p/16915470.html">这篇博客</a>。</li><li>另外，如果两个store之间存在FENCE指令，那么也不可以合并写入。</li></ul></li></ul></li><li>（2）Simpler Support for Core Speculation</li><li>（3）Coupling Consistency and Coherence<ul><li>在SC/TSO模型中，我们认为缓存一致性相关的设计是一个黑盒。</li><li>在RMO模型中，可以将缓存一致性的黑盒打开，允许部分CPU从storebuffer中取新值，也允许部分CPU从cache中取旧值。<ul><li>当然，可能需要多个CPU共享一个store buffer或是共享一个L1DCache。</li></ul></li></ul></li></ul><h4 id="xc-example-relaxed-consistency-model">2.4.3 XC (Example RelaxedConsistency Model)</h4><ul><li>这里举一个例子来帮助理解松散一致性内存模型。</li><li>设内存操作顺序遵循下面规则<ul><li>该模型默认 load 和 store操作是无序的，程序员可以在需要严格排序时使用FENCE指令。</li><li>一个CPU中，FENCE指令也是有先后顺序的。</li><li>当前CPU中的FENCE指令不会影响其它CPU中的内存操作顺序。</li><li>XC模型中只维护 访问相同地址的两个操作间 的TSO排序规则。<ul><li>Load - Load to the same address</li><li>Load - Store to the same address</li><li>Store - Store to the same address</li></ul></li><li>XC模型确保在load操作也会检查store buffer。</li></ul></li><li>在XC模型下使用FENCE<ul><li><p>如下表所示，F1:FENCE指令排序了Store操作，让C1为data1和data2赋值完新值后，再为flag赋值为SET。</p></li><li><p>F2:FENCE指令是为了防止L2,L3和L1发生重排序。</p><p><img src="3201119-20231007141039245-1469699710.png" style="zoom:50%;"/></p></li></ul></li><li>XC 实现方法<ul><li>TSO 模型中由于存在store buffer，导致store-load可能会发生重排序；XC模型中添加Reorder Unit，来完成load和store之间的重排序。</li><li>与前面介绍的模型一样，可以使用Switch简单的实现，或是使用带缓存一致性的内存模型实现。</li><li>Switch结构<ul><li>对于每个Core，load/store以及FENCE指令按照Ci的程序顺序给到ReorderUnit单元的队尾。</li><li>重排序单元根据程序顺序/XC模型内存操作顺序规则 进行重新排序。</li><li>当Switch选择Ci时，会执行Ci的Reorder Unit队首的load/store操作。</li></ul></li><li>带缓存一致性 内存模型<ul><li><p>和TSO/SC一样，将重排序规则的实现和cachecoherence的实现分割开，不同的是增加了Reorder Unit。</p><p><img src="3201119-20231008133755888-219165500.png" style="zoom:50%;"/></p></li></ul></li></ul></li><li>XC 内存模型下的原子操作<ul><li>假设XC 内存模型下，存在多个core，每个core通过一个 non-fifoCoalescing Write Buffer 连接到 Memory System。</li><li>XC内存模型下的原子操作实现可以借用TSO模型，但不需要在RMW操作之前清空storebuffer，因为XC模型允许不同地址的store和load乱序操作。</li><li>RMW操作可用于加锁，如下表，分别为在TSO模型和XC模型下进行加锁和解锁的操作。<ul><li><p>TSO 模型下，使用原子RMW操作进行加锁，加锁之后完成Critical Section部分的load和store操作，最后向L中写入0，表示解锁。</p><ul><li>我个人认为需要在RMW和CriticalSection之间添加一个FENCE指令。因为可能会发生RMW中store操作和CriticalSection中的load操作进行重排序。</li></ul></li><li><p>XC 模型下，由于不会限制Critical Section部分内存操作和RMW之间进行重排序，所以需要添加FENCE指令，另外在CriticalSection 和解锁之间也要插入一个FENCE指令，防止解锁语句和之前的语句发生重排序。</p><p><img src="3201119-20231010102001410-1309634596.png" style="zoom:50%;"/></p></li></ul></li></ul></li></ul><h4 id="无数据竞争drf程序的一致性模型">2.4.4无数据竞争（DRF）程序的一致性模型</h4><ul><li>同步模型<ul><li>RMO通过放松对内存操作顺序的限制，来给编译器和硬件更多的优化空间，从而提高性能。</li><li>如果程序遵守<strong>特定的限制</strong>，那么程序仍能呈现出SC的效果。</li><li>这个<strong>特定的限制</strong>可以通过同步操作实现，这个同步操作是硬件可以支持的，以C语言中的test_and_set()函数为例。特定的限制也可以称为<strong>同步模型</strong>。</li></ul></li><li>Data-Race-Free是同步模型中的一种，一个程序遵循Data-Race-Free同步模型，需要满足<ul><li>所有的同步操作都可以由硬件支持(recognized by hardware)。</li><li>在一个理想的系统上(内存操作都是原子的而且按程序顺序)，所有的<strong>有冲突的内存操作</strong>都具有happens-before关系。<ul><li>其中有冲突的内存操作是指：两个内存操作针对同一地址，其中至少有一个是写操作。</li><li>happens-before 更为具体的解释可以看<ahref="https://zhuanlan.zhihu.com/p/433467241">这篇博客</a>.</li></ul></li></ul></li><li>在 RMO模型下，使用FENCE、RMW等同步操作来确保DRF，那么程序也会呈现出顺序一致性(SC)的效果。</li><li>举例，如下表。<ul><li><p>两者区别在于上表中C2没有同步操作，而下表的C1和C2都通过添加FENCE指令和RMW加锁来实现同步操作。</p></li><li><p>上表中C2没有使用同步操作，所以C2的load操作可能会和C1的store操作同时进行，从而出现数据争用的情况。最后(r1,r2)的值可能会有四种情况。</p></li><li><p>下表中C2和C1使用的是同一个锁（L变量），那么C1的 Critical Section只能在C2之前执行，或是C2的 Critical Section 只能在C1之前执行。</p><ul><li>所以下表的执行结果只能是(r1,r2)=(0,0)/(NEW,NEW).</li></ul><p><img src="3201119-20231011190906128-1149913925.png" style="zoom:50%;"/></p><p><img src="3201119-20231011190932117-1021057976.png" style="zoom:50%;"/></p></li></ul></li><li>一些定义<ul><li>内存操作可以分为两类，一类为<strong>同步操作</strong>(synchronizationoperations)，还有一类为<strong>数据操作</strong>（data operations）.<ul><li>其中同步操作包括锁的获取和释放，以及FENCE指令等。</li></ul></li><li>如果两个<strong>数据操作</strong>Di、Dj来自不同的核，访问相同的内存位置，且至少有一个数据操作是store，那么会发生<strong>冲突</strong>。</li><li>如果两个<strong>同步操作</strong>Si、Sj来自不同的核，访问相同的内存位置，且至少有一个同步操作是store，那么会发生<strong>冲突</strong>。</li></ul></li></ul><h4 id="release-consistency">2.4.5 Release Consistency</h4><ul><li>松散内存模型根据不同的设置可变形为多种。</li><li>上表中，对所有的同步操作都用FENCE指令来前后包围太过于浪费性能。<ul><li>实际上，只需要F12,F13和F22,F23。</li><li>其中F1124删除掉也没关系，C2的Critical Section和C1的CriticalSection不会相互干扰。</li></ul></li></ul><h4 id="因果关系-写原子性">2.4.6 因果关系 &amp; 写原子性</h4><ul><li><p>下面介绍RMO的两个属性：因果关系和写原子性</p></li><li><p>因果关系（causality）</p><ul><li>如下图，L1可能发生在S1之前，但是由于B1-L1之间不断循环，直到满足条件才可以执行后续S2的store操作。C2和C3的关系与此类似。</li><li>如果L3操作中r3的值为NEW，那么因果关系成立。如果r3的值为0，那么因果关系被破坏。</li></ul><p><img src="3201119-20231024093214632-673248065.png" style="zoom:50%;"/></p></li><li><p>写原子性（write atomicity）</p><ul><li>一个core的Store操作可以立即被其它core看到。</li><li>前面介绍的<strong>XC模型</strong>，在定义上也是<strong>遵循写原子性的</strong>，可通过内存屏障指令指定在此指令之后store的数据从storebuffer中读出到cache/内存中，被其它core看见。</li><li>另外写原子性允许当前core的写操作可以先被当前core观察到，之后再被其它core观察到。类似于2.3.1节介绍的TSO例2.</li></ul></li><li><p>因果关系 &amp; 写原子性</p><ul><li>写原子性可以保证正确处理IRIW (Independent Read Independent Write)。<ul><li><p>举例如下表格，假设<strong>不满足写原子性。</strong></p><ul><li>假设C1和C3是一个多线程core的两个线程上下文，它们共享一个storebuffer。C2和C4也是如此。</li><li>如果不满足写原子性，那么C1执行S1操作时，此时C3只能看到S1操作的结果。同理，C4只能看到S2操作的结果。</li><li>此时r2和r4的值均为0。没有正确处理IRIW操作。</li></ul><p><img src="3201119-20231024094205072-307274823.png" style="zoom:50%;"/></p></li><li><p>正确处理IRIW不能保证写原子性。</p></li></ul></li></ul></li></ul><h3 id="risc-v-weak-memory-orderrvwmo">2.5 RISC-V Weak MemoryOrder(RVWMO)</h3><ul><li>RVWMO 可以看成是RC和XC的混合体。<ul><li>RVWMO内存顺序与XC一致，并存在几种FENCE指令的变体。</li><li>RVWMO的load和store操作可以携带一些属性，与RC一致。<ul><li>其中load指令可以携带ACQUIRE，存储指令可以携带RELEASE。RMW指令可以携带Release/Acquire或者两者同时。<br /></li><li>ACQUIRE在RVWMO中分为ACQUIRE-RC_PC和ACQUIRE-RC_SC，RELEASE分为RELEASE-RC_PC和RELEASE-RC_SC。load/store可以携带任意一种ACQURE/RELEASE，RMW只能选择RC_SC。</li><li>其中PC为Processor Consistency，而SC为Sequential Consistency。</li></ul></li></ul></li><li>FENCE 指令<ul><li>fence 指令格式如下。<ul><li>其中两个参数分别为predecessor和successor。前者指示fence指令前的操作，后者指示fence指令后的操作。</li><li>参数指示栅栏对哪种类型的访问进行排序，这些类型可以是：内存读取（r）、内存写入（w）、设备输入（i）以及设备输出（o）。</li></ul><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs llvm"><span class="hljs-keyword">fence</span> pred<span class="hljs-punctuation">,</span> succ    <br></code></pre></td></tr></table></figure></li><li>XC中的FENCE指令为fencerw,rw.即保证fence之后所有的load/store操作都不会出现在fence之前的load/store操作之前。</li><li>除此之外，还有五种组合，包括 <figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs llvm"><span class="hljs-keyword">fence</span> rw<span class="hljs-punctuation">,</span>w<span class="hljs-comment">;</span><br><span class="hljs-keyword">fence</span> r<span class="hljs-punctuation">,</span>rw<span class="hljs-comment">;</span><br><span class="hljs-keyword">fence</span> r<span class="hljs-punctuation">,</span>r<span class="hljs-comment">;</span><br><span class="hljs-keyword">fence</span> w<span class="hljs-punctuation">,</span>w<span class="hljs-comment">;</span><br><span class="hljs-keyword">fence</span>.tso<br># 其中<span class="hljs-keyword">fence</span>.tso指令是<span class="hljs-keyword">fence</span>的变种，相当于<span class="hljs-keyword">fence</span> rw<span class="hljs-punctuation">,</span>rw<span class="hljs-comment">; 除去store load之间的约束，允许store-load重排序。</span><br></code></pre></td></tr></table></figure></li></ul></li><li>语法依赖<ul><li><p>RVWMO在某些方面约束要比XC要强，例如：地址、数据或控制依赖可以约束RVWMO中的内存顺序。</p></li><li><p>参考<ahref="https://gitee.com/laokz/OS-kernel-test/blob/master/memorder/riscv.md">这篇文章</a>，语法依赖可以认为是一条指令的源操作数与前面指令（不一定相邻）的目的操作数是同一个寄存器；因此必须前面指令执行结束后才可以进行后续指令。</p><ul><li>注意<ul><li>（1）是否存在语法依赖看寄存器名，而不是值。</li><li>（2）并不是所有指令都有目的操作数；所以没有指令会依赖这种指令。</li><li>（3）x0寄存器不构成任何依赖；因为它的值是固定的、已知的。</li><li>（4）语法依赖具有传递性，例如：B依赖A，C依赖B，那么C依赖A。即全局内存操作顺序A必在C之前。<ul><li><p>举例如下，其中b依赖于a，而c依赖于b，d依赖于c。因此，尽管a和d并不相关，但也被强制的制定了执行顺序。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">(a) ld <span class="hljs-built_in">a1</span>,<span class="hljs-number">0</span>(<span class="hljs-built_in">s0</span>)<br>(<span class="hljs-keyword">b) </span><span class="hljs-keyword">xor </span><span class="hljs-built_in">a2</span>,<span class="hljs-built_in">a1</span>,<span class="hljs-built_in">a1</span><br>(c) <span class="hljs-keyword">add </span><span class="hljs-built_in">s1</span>,<span class="hljs-built_in">s1</span>,<span class="hljs-built_in">a2</span><br>(d) ld <span class="hljs-built_in">a5</span>,<span class="hljs-number">0</span>(<span class="hljs-built_in">s1</span>)<br></code></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li><li><p>语法依赖按照寄存器的用途分为三类，并都需要保证正确的执行顺序。</p><ul><li><p>地址依赖：前一条指令的目的寄存器结果是后面访存指令的操作地址，用法类似于指针。如下图所示。</p><p><img src="3201119-20231024150824221-1929559695.png" style="zoom:50%;"/></p></li><li><p>数据依赖：前一条指令的目的寄存器结果是后面指令的操作数。如下图所示。</p><p><img src="3201119-20231024150848949-1465640225.png" style="zoom:50%;"/></p></li><li><p>控制依赖：两条指令之间存在一个依赖于第一条指令的<strong>分支/间接跳转指令</strong>，判断语句依赖于前面指令的目的寄存器结果。条件语句对后续的所有指令构成控制依赖。但在RVWMO模型中，仅保证后续的store指令有序。</p><ul><li>如下图所示，需保证顺序L1-B1-S1。</li></ul><p><img src="3201119-20231024150912913-1898672627.png" style="zoom:50%;"/></p></li></ul></li><li><p>除了前面介绍的三种语法依赖，RISC-V还存在流水线依赖。举例如下。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">       代码<span class="hljs-number">1</span>         代码<span class="hljs-number">2</span>          代码<span class="hljs-number">3</span>          代码<span class="hljs-number">4</span><br>-------------------------------------------------------------<br>(a) <span class="hljs-keyword">lw </span><span class="hljs-built_in">t0</span>, (<span class="hljs-built_in">s0</span>)   <span class="hljs-keyword">lw </span><span class="hljs-built_in">t0</span>, (<span class="hljs-built_in">s0</span>)   <span class="hljs-keyword">lw, </span><span class="hljs-built_in">t0</span>, (<span class="hljs-built_in">s0</span>)   <span class="hljs-keyword">lw, </span><span class="hljs-built_in">t0</span>, (<span class="hljs-built_in">s0</span>)<br>(<span class="hljs-keyword">b) </span><span class="hljs-keyword">sw </span><span class="hljs-built_in">t1</span>, (<span class="hljs-built_in">t0</span>)   <span class="hljs-keyword">sw </span><span class="hljs-built_in">t0</span>, (<span class="hljs-built_in">t1</span>)   <span class="hljs-keyword">sw, </span><span class="hljs-built_in">t1</span>, (<span class="hljs-built_in">t0</span>)   <span class="hljs-keyword">lw, </span><span class="hljs-built_in">t1</span>, (<span class="hljs-built_in">t0</span>)<br>(c) <span class="hljs-keyword">lw </span><span class="hljs-built_in">t2</span>, (<span class="hljs-built_in">t0</span>)   <span class="hljs-keyword">lw </span><span class="hljs-built_in">t2</span>, (<span class="hljs-built_in">t1</span>)   <span class="hljs-keyword">sw, </span><span class="hljs-built_in">t2</span>, (<span class="hljs-built_in">s1</span>)   <span class="hljs-keyword">sw, </span><span class="hljs-built_in">t2</span>, (<span class="hljs-built_in">s1</span>)<br></code></pre></td></tr></table></figure><ul><li>上面描述的4段代码，都是前两条指令构成语法依赖。</li><li>代码1和代码2约束点为：<strong>在store地址或者值未知时，不能load这个store的值。</strong>因此(b)store操作的值或地址不能确定时，不能执行(c).又因为(b)依赖于(a)，所以(c)依赖于(a)。</li><li>代码3和代码4约束点为：<strong>前面的load/store地址未知时不能进行store。</strong>因为对于同一地址，不可发生写超前。<ul><li>例如将写操作提前进行，前一条指令操作（写/读）也是针对同一地址，那么可能会发生写错旧值覆盖新值/读新值覆盖读旧值。因此(b)地址未确定时，(c)不能执行。而(b)依赖于(a)，所以(c)不能超前于(a)。</li></ul></li></ul></li></ul></li><li>对同一地址的约束<ul><li>对于同一地址，要求满足load-store，store-store顺序，可以进行store-load以及 load-load重排序。除此之外，还需要满足下面的要求：<ul><li>（1）写不超前<ul><li>针对同一地址，store指令不可以超前于前面一条的指令。与上面介绍的代码3和代码4约束点的解释一致。（也就是上面需要满足的load-store，store-store顺序）</li></ul></li><li>（2）读CoRR(Coherence for Read-Read pairs)<ul><li>对于同一个地址的两个读，只要后一个load不会得到相较于前一个load更旧的值，就可以<strong>不约束</strong>两者的内存顺序。</li></ul></li><li>（3）原子操作<ul><li>因为原子指令中会存在store操作<ul><li>当store位于程序顺序后面时不会超前到前面指令。</li><li>当store位于程序顺序前面时，如果后面是store操作时，也不可超前；如果后面操作是load时，规定也不可以乱序，为了保证原子指令的操作语义。</li></ul></li></ul></li></ul></li><li>举例1<ul><li>下面代码中，如果想要产生outcome输出，那么需要满足：<ul><li>（d）这里被插入bubble，可能是为了等待其它指令执行完成。（为什么插入bubble，并且在(d)处结束不理解）</li><li>（e）执行sw操作，将写入数据t2写入store buffer中。</li><li>（f）执行lw操作，并从storebuffer中读出对应地址的数据，即<strong>a1=t2=2</strong>.</li><li>（g）执行异或运算得到t3=0.</li><li>（h）执行加法运算得到s0=s0.</li><li>（i）执行lw操作，将s0地址处数据load出来，此时未有写入数据，所以<strong>a2=0.</strong></li><li>（a）执行sw操作，写入core0对应的storebuffer中，再获得其它core返回的invalid回执之后再写入cache/内存中。</li><li>（c）执行sw操作，与上面（a）相同，将数据t1写入内存地址为s1处。</li><li>（d）bubble结束，开始执行lw操作，load对应地址的数据，即<strong>a0=t1=1</strong>.</li></ul></li><li>若考虑可能发生的内存重排序，那么过程为：<ul><li><strong>内存操作顺序</strong>应为：<strong>f-i-a-c-d-e</strong><ul><li>考虑到写不超前，（d）和（e）的顺序不可发生变化。（i）应在（a）前面。</li><li>考虑到fence指令，（a）应在（c）前面。</li><li>考虑到CoRR，（f）和（d）之间存在对同一个地址的sw语句（e），因此允许（f）在内存顺序上超前于（d）。<ul><li>因为流水线结构，即使（f）排序到（e）前面，但仍可以在load时从前面的sw操作获取数据直接给到（f），所以load也不会出错。</li></ul></li></ul></li></ul><pre><code class="hljs">    Hart 0            Hart 1-------------------------------------    li t1, 1          li t2, 2(a) sw t1,0(s0)   (d) lw a0,0(s1)(b) fence w, w    (e) sw t2,0(s1)(c) sw t1,0(s1)   (f) lw a1,0(s1)                  (g) xor t3,a1,a1                  (h) add s0,s0,t3                  (i) lw a2,0(s0)Outcome: a0=1, a1=2, a2=0（允许）</code></pre></li></ul></li></ul></li></ul><h3 id="consistency-coherence">2.6 Consistency &amp; Coherence</h3><ul><li>Coherence问题：<ul><li>当一份数据有多份拷贝时，可能会发生coherent问题。</li><li>对于单核，数据可能会同时出现在cache和主存中，此时会发生coherent问题。</li><li>对于多核，数据可能会在多个core的cache中或是在主存中，此时也容易发生coherent问题。</li></ul></li><li>Cosistent问题：<ul><li>当一块内存区域被多个Master进行读写时，可能会出现cosistent问题。</li><li>需要保证多个master读写顺序，以及对cache进行性能优化时可能会导致的重排序也可能引起cosistent问题。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>栈 &amp; 堆</title>
    <link href="/2023/11/01/%E6%A0%88%20&amp;%20%E5%A0%86/"/>
    <url>/2023/11/01/%E6%A0%88%20&amp;%20%E5%A0%86/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://blog.csdn.net/qq_52505851/category_12399093.html"class="uri">https://blog.csdn.net/qq_52505851/category_12399093.html</a></li><li><a href="https://blog.csdn.net/hanlin1985/article/details/3132210"class="uri">https://blog.csdn.net/hanlin1985/article/details/3132210</a></li><li><a href="https://www.cnblogs.com/wahahahehehe/p/15164437.html"class="uri">https://www.cnblogs.com/wahahahehehe/p/15164437.html</a></li><li><a href="https://www.cnblogs.com/lesroad/p/10389971.html"class="uri">https://www.cnblogs.com/lesroad/p/10389971.html</a></li></ul></li></ul><hr /><h2 id="栈-寄存器">1. 栈 &amp; 寄存器</h2><ul><li><p>栈的用处</p><ul><li>（1）RISC-V划分了x10-x17八个寄存器为参数寄存器，用于传递参数或返回值。考虑到如果参数/局部变量很多，8个寄存器放不下，那么需要开辟栈空间存储。</li><li>（2）用于保护和恢复函数调用过程中的相关信息，如返回地址、上下文寄存器信息等。这些信息可以帮助函数（中断）在执行完毕后返回到正确的位置。</li></ul></li><li><p>栈：后进先出（LIFO），栈指针指向栈的顶部，从高地址向低地址，为压栈过程，存入数据；从低地址向高地址，为弹栈过程，取出数据。</p><ul><li>下面代码中，由于diffofsums()函数，出现无条件跳转指令。当参数寄存器足以使用，那么不需要开辟栈空间。</li></ul><p><img src="3201119-20230906220555789-544830672.png" /></p><ul><li>如果参数寄存器不足以使用，可以将参数先压入栈中，需要使用时再从栈中取出。临时寄存器在<strong>使用之后</strong>不需要弹栈恢复。</li><li>如果为了避免函数调用修改掉主寄存器中的内容，可以通过下面步骤实现。<ul><li>在栈上分配空间存储对应数目的寄存器值。</li><li>将寄存器s3,t0,t1的值存到栈上，等待函数运算结束之后，再从栈中取出恢复寄存器旧值。</li><li>使用寄存器进行相对应的运算。</li><li>将运算后的结果给到调用者层的寄存器a0。</li><li>将栈中的其它值弹出，恢复寄存器s3,t0,t1的旧值。</li><li>释放栈空间。</li></ul></li></ul><p><img src="3201119-20230906222236489-589165970.png" /></p><ul><li>每个函数有自己的栈空间，也只能访问自己的栈。</li></ul></li><li><p>为了减少压栈和栈弹出的次数，RISC-V将19个寄存器分为了两组：</p><ul><li>临时寄存器：调用者不会再使用他们，所以不需要被保存和恢复（压栈/弹栈）。如上面代码中的t0，t1.（x5-x7,x28-x31）</li><li>保存寄存器：希望在调用前后需要保持相同值的寄存器，需要压栈/弹栈。如上面代码中的s3，在调用函数之后需要其仍未调用前的旧值.（x8-x9,x18-x27）</li></ul><p><img src="3201119-20230906232325563-433575287.png" /></p></li><li><p>嵌套过程</p><ul><li>非叶函数：是指调用了其它函数或者改变非易失性寄存器的函数。<ul><li>非易失性寄存器：在断电后仍能保持内容不变的寄存器，常用于保存一些重要的数据或状态，如程序计数器、栈指针、返回地址等。</li><li>易失性寄存器：在断电后，会丢失其内容的寄存器，常用于保存一些临时的数据或操作数，例如通用寄存器、浮点寄存器、向量寄存器等。</li><li>一般来说，被调用函数需要保护（压栈/弹栈）非易失性寄存器的值。而被调函数可以自由的使用易失性寄存器的值，不需要保存/恢复它们的值。</li></ul></li><li>在非叶函数调用时，遵循下面两条规则：<ul><li>调用者保存规则：调用者需要将所有调用后还需要的参数存储器或临时存储器压栈保存。</li><li>被调用者保存规则：被调用者将返回地址寄存器x1和被调用者使用的保存寄存器压栈。</li></ul></li><li>代码示例如下所示。</li></ul><p><img src="3201119-20230907111834366-1859723362.png" /></p></li></ul><h2 id="堆">2. 堆</h2><ul><li>堆和栈的区别<ul><li>栈：后进先出（LIFO），由编译器自动分配和释放。使用一级缓存，调用完立即释放。</li><li>堆：可对任意位置进行操作，通常由程序员手动分配，使用完需及时释放(free)，不然容易造成内存泄漏。</li><li>更为详细的介绍可以看<ahref="https://blog.csdn.net/hanlin1985/article/details/3132210">这篇博客</a>。</li></ul></li><li>下图为Linux操作系统下RISC-V分配内存的规定。<ul><li>栈从用户地址空间的<strong>高端向下生长</strong>。<ul><li>函数内局部变量的存储单元都可以在栈上创建，并在函数执行结束时这些存储单元自动被释放。</li><li>栈内存分配运算<strong>内置于处理器的指令集</strong>中，效率很高，但是分配的内存容量有限。</li></ul></li><li>内存的低端是保留的，再往上是RISC-V的机器代码，称为代码段。</li><li>再往上是静态数据段，用于存放静态数据、全局数据和常量。</li><li>再往上就是堆<ul><li>对于链表这类数据结构，往往随着生命周期增长或缩短，存放在堆内。</li><li>关于数组是存放在栈/堆/静态数据段，主要看是如何声明的。<ul><li>如果是程序员 new malloc， 则是存放在堆中的。</li></ul></li></ul></li><li>堆和栈是相向生长，随着两个段的此消彼长达到内存的高效使用。</li></ul></li></ul><p><img src="3201119-20230918160341670-703117698.png" style="zoom:33%;" /></p><ul><li>程序员可以通过显示函数调用来分配(malloc)和释放(free)堆上的空间。<ul><li>如果忘记释放空间，可能会导致内存泄漏，最终耗尽大量内存。</li><li>如果过早释放空间，可能会导致悬空指针，导致指针指向错误的位置。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RISC-V 指令</title>
    <link href="/2023/11/01/RISC-V%20%E6%8C%87%E4%BB%A4/"/>
    <url>/2023/11/01/RISC-V%20%E6%8C%87%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li>《计算机组成与设计 第五版》</li><li>《RISC-V-Reader-Chinese-v2p1》（包云岗老师）</li><li>《手把手教你设计CPU RISC-V处理器》</li><li><ahref="https://blog.csdn.net/qq_38915354/article/details/115696721"class="uri">https://blog.csdn.net/qq_38915354/article/details/115696721</a></li><li><a href="https://zhuanlan.zhihu.com/p/374235855"class="uri">https://zhuanlan.zhihu.com/p/374235855</a></li><li><ahref="https://blog.csdn.net/weixin_46623752/article/details/125770550"class="uri">https://blog.csdn.net/weixin_46623752/article/details/125770550</a></li><li><a href="https://blog.csdn.net/sucaiwa/article/details/129328891"class="uri">https://blog.csdn.net/sucaiwa/article/details/129328891</a></li></ul></li></ul><hr /><h2 id="寄存器相关">1. 寄存器相关</h2><ul><li>RISC-V架构可选32bit（RV32）/64bit(RV64)，可选32个寄存器（I架构）/16个寄存器（E架构）。<ul><li>考虑<strong>整数通用寄存器组</strong>：其中0寄存器被预留为常数0，其余31/15个寄存器为通用整数寄存器。</li><li>考虑<strong>浮点寄存器组</strong>（一般为F/D类扩展指令集），有32个通用浮点寄存器；寄存器位宽由扩展指令集类型决定，F类：单精度、32bit，D类：双精度、64bit。</li></ul></li><li>RISC-V 的汇编语言是对寄存器的数据进行处理。<ul><li>算术运算（加、减、立即数加）。</li><li>数据传输（取：从存储器取数据到寄存器；存：从寄存器读数据存到存储器，更多关于存储器访问指令下面有介绍）。</li><li>逻辑运算（与，或，异或...）。</li><li>移位操作（逻辑左/右移，算数左/右移）。</li><li>条件分支（相等、不等、大于、小于跳转）。</li><li>无条件跳转（跳转 - 链接）。</li></ul></li><li>存储器访问指令<ul><li>对于更复杂的数据结构（例如数组和结构体）包含比寄存器更多的数据元素，只能存放于存储器中，使用数据传输指令进行读取。</li><li>与RISC架构策略一致，只有Load和Store指令可以访问存储器，其它指令都不可访问存储器。</li><li>存储器读写指令基本单位是<strong>字节（Byte）</strong>。</li><li>RISC-V架构存储模式只支持小端格式。</li><li>RISC-V推荐使用地址对齐的存储器读写操作，但也支持地址非对齐。</li><li>RISC-V架构的考虑硬件架构复杂度，<strong>不支持读写指令下存储地址自增/自减的模式。</strong></li></ul></li></ul><h2 id="rv32i-指令格式">2. RV32I 指令格式</h2><ul><li>下图介绍了六种基本指令格式<div data-align="center"><img src="3201119-20230702170812050-2086168818.png" width = 60%/></div></li><li>R-type<ul><li>实现rs1，rs2两个寄存器的值运算，并将运算后的结果存在rd中。opcode 和func 共同决定实现哪种运算。</li></ul></li><li>I-type<ul><li>可以实现带一个常数的算数指令以及Load指令。注意immediate字段为补码值。<br /></li><li>对于Load指令：可以取相对于rd中的基地址+imm字节的数据。<ul><li>例如下面的指令，从x22寄存器中获取基地址，并加上偏移地址（64/8bit =8Byte） ，取出字，放到x9寄存器中。<ul><li>其中(x)22放在rs1寄存器中，(x)9放在rd字段，64放在imm字段。<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">lw</span> <span class="hljs-built_in">x9</span>, <span class="hljs-number">64</span>(<span class="hljs-built_in">x22</span>)<br></code></pre></td></tr></table></figure></li></ul></li></ul></li><li>考虑到逻辑操作中的<strong>移位</strong>，使用的也是I型指令格式，考虑到寄存器位宽为32bit，所以shamt也不会超过32，所以imm只需要划出5bit空间，其余几bit作为额外的操作码字段。</li></ul></li><li>S-type<ul><li>用于Store指令，immediate字段仍为补码值。</li><li>存在两个源寄存器，一个存放基址，一个存放数据。</li><li>设计选择与R-type保持类似的指令格式，将imm进行拆分，可以一定程度降低硬件的复杂性。<ul><li>例如下面的指令，x9中写着要存入的值，x10中写着存储器基地址，并加上偏移地址（240/8bit= 30Byte）。<ul><li>其中(x)9放在rs2字段中，(x)10放在rs1字段中，240放在imm字段中（要被拆分）。<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">sw</span> <span class="hljs-built_in">x9</span>, <span class="hljs-number">240</span>(<span class="hljs-built_in">x10</span>)<br></code></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li><li>U-type<ul><li>I、S型指令格式中已经有12bitimm，但是需要考虑有时常数很大，12bit不够，此时可以使用LUI指令。<ul><li>将高20bit常数加载到寄存器的第31-12bit，低12bit用常数0填充。之后可以使用addi 指令与低12bit立即数相加，以实现对32bit寄存器数值的配置。</li><li>需要注意：ADDI指令处理的立即数为有符号数，使用ADDI指令加上低12bit时，如果12bit最高位为1，那么做的是减法而不是加法。<ul><li>此时需要进行补值，对于 ADDI的12bit最高位为1的情况，加上2^12即可。相关处理可以看<ahref="https://zhuanlan.zhihu.com/p/374235855">这篇文章</a>。</li></ul></li></ul></li></ul></li><li>B-type<ul><li>比较两个源寄存器rs1和rs2，并进行跳转。</li><li>例子如下：<ul><li>指令格式上可以看到imm[0]被舍弃掉了，因为该bit被设置为0；汇编器根据label的地址计算出相对当前PC值的偏移量为16bytes= 'b1_0000，映射如下图。 <figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-keyword">beq</span> <span class="hljs-built_in">x19</span>, <span class="hljs-built_in">x10</span>, label<br></code></pre></td></tr></table></figure><div data-align="center"><img src="3201119-20230702221434146-1599458281.png" width = 60%/></div></li></ul></li><li>看到这里，其实就会有一个疑问，为什么B型和J型立即数在inst中分散的奇奇怪怪，但是寄存器却是固定位置的，知乎上搜到了这个问题的一些<ahref="https://www.zhihu.com/question/405003253">回答</a>。我认为其中有一个解释的很有道理，为了平衡（寄存器索引到读出寄存器值的时间）和（通过inst生成参与操作的立即数选择逻辑的时间），提高整体的运算速度。</li></ul></li><li>J-type<ul><li>主要用在无条件跳转指令jal和jalr上。 <figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dos">jal <span class="hljs-built_in">rd</span>, <span class="hljs-built_in">label</span><br>jalr <span class="hljs-built_in">rd</span>, rsl, imm<br></code></pre></td></tr></table></figure></li><li>jal<ul><li>主要实现两步：<ul><li>J-type和前面介绍的B-type一样，舍弃掉imm[0]，强制设置该bit为0；将imm偏移量加到该指令的PC值，得到最终跳转目标地址。RV32I的J指令格式中imm有21bit，但是imm[0]被舍弃掉了，因此可以跳转±2^(21-1)= ±1MB，其中21-1是因为有1bit的符号位。<br /></li><li>并且将下一条指令的PC（当前指令PC值+4）写入寄存器rd中。+4是因为对于RV32I来说，其指令长度为4个字节，且使用字节寻址。将下一条地址写入寄存器中，是为返回做准备。</li></ul></li></ul></li><li>jalr<ul><li>！！<strong>注意，jalr不是J型指令格式而是I型指令格式。</strong></li><li>imm的12bit立即数为偏移量，基地址保存在rs1中，两者相加为最终跳转的目标地址。只能跳转±2KB（2^11=2KB，去掉符号位）。</li><li>jalr也需要将下一条指令的PC值写入rd寄存器中。<div data-align="center"><img src="3201119-20230702233922982-373352789.png" width = 60%/></div></li></ul></li></ul></li></ul><h2 id="risc-v-寻址模式">3. RISC-V 寻址模式</h2><ul><li>PC 相对寻址<ul><li>前面介绍的B型和J型都是分支跳转指令；前者的寻址范围为基于当前PC值-4096~4096，后者的寻址范围为基于当前PC值 -2^(20) ~ 2^(20).</li></ul></li><li>基址寻址<ul><li>如S型指令。</li></ul></li><li>寄存器寻址<ul><li>如R型指令。</li></ul></li><li>立即数寻址<ul><li>如I型指令。<div data-align="center"><img src="3201119-20230921162921388-1215879610.png" width = 60%/></div></li></ul></li></ul><h2 id="risc-v-原子指令">4. RISC-V 原子指令</h2><ul><li>对于单处理器，任务之间的同步机制可以通过<strong>加锁和解锁</strong>实现。</li><li>对于多处理器有以下方法。</li></ul><h3 id="硬件原语">4.1 硬件原语</h3><ul><li>通过一组硬件原语（例如CAS、TAS、TTAS、FAA），实现在进行内存单元读取和写入之间不能插入其他操作。<ul><li>程序员需要使用一些基本的硬件原语来构建同步原语库。原语相关的解释可以看<ahref="https://baike.baidu.com/item/%E5%8E%9F%E8%AF%AD">这篇文章</a>，其主要特点为在执行过程中不可被中断。</li><li>考虑到使用单条同步原语对处理器的设计要求较高，因为需要在单条不可中断的指令中完成存储器的读和写操作。</li></ul></li></ul><h3 id="原子指令">4.2 原子指令</h3><h4 id="lrsc">4.2.1 lr/sc</h4><ul><li><p>使用指令对，第二条指令返回一个值，该值表示指令对是否被原子执行。没有<strong>其他处理器</strong>在该指令对之间执行，则可认为是完成原子操作。</p><ul><li>在RISC-V中，该指令对为lr(load reserved)和sc(store conditional).</li></ul></li><li><p>lr指令格式如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">lr.&#123;w/d&#125;.&#123;aq/rl&#125; rd, (rs1)<br></code></pre></td></tr></table></figure><ul><li>其中w/d分别对应为word（32bits）和double word（64bits）。</li><li>其中aq/rl分别对应为acquire/release。lr和sc可以通过这两个后缀添加额外的内存访问顺序限制。具体会在内存访问相关内容的<ahref="https://www.cnblogs.com/qianbinbin/p/17723730.html">博客</a>中进行介绍。<ul><li>注意：成功的sc才代表这个原子指令的执行，失败的sc不产生任何内存操作，自然也不会对内存访问顺序的约束产生任何影响。</li></ul></li><li>其中{}中的内容不是必须填写的，编译器能够根据当前的运行环境自动进行设置。<br /></li></ul></li><li><p>sc指令格式如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sc.&#123;w/d&#125;.&#123;aq/rl&#125; rd, rs2, (rs1)<br></code></pre></td></tr></table></figure><ul><li>与lr指令参数含义相同。</li></ul></li><li><p>lr/sc 指令伪代码描述</p><ul><li>第2行，从rs1地址处取数据加载到rd寄存器中。</li><li>第3行，在rs1内存地址上设置保留标记(reservation set)。</li><li>第5行，在将rs2寄存器的数据写到rs1地址之前，会首先检查rs1内存地址是否有设置保留标记。<ul><li>如果有，那么将rs2寄存器的数据写入rs1内存地址中；并将rd寄存器的值设置为0.表示保存成功。</li><li>如果没有，则不完成保存rs2寄存器数据到rs1内存地址的过程，并向rd寄存器写入一个非零值，表示保存失败。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//lr指令</span><br>rd = [rs1]<br>reservation_set(cur_hart)<br><span class="hljs-comment">//sc指令</span><br><span class="hljs-keyword">if</span> (is_reserved(rs1)) &#123;<br>    *rs1 = rs2<br>    rd = <span class="hljs-number">0</span><br>&#125; <span class="hljs-keyword">else</span><br>    rd = <span class="hljs-number">1</span><br>clean_reservation_set(cur_hart)<br></code></pre></td></tr></table></figure></li><li>根据上面的描述，我们发现sc指令并不是一定会执行成功，需要满足下面几个条件：<ul><li>（1）lr/sc指令需要访问相同的地址。</li><li>（2）lr和sc指令之间没有其它的写操作访问同样的地址。</li><li>（3）lr和sc指令之间没有任何的中断和异常发生。</li><li>（4）lr和sc指令之间没有执行mret指令。<ul><li>其中mret指令可用作机器模式转换为用户模式。更多信息可在网上检索。</li></ul></li></ul></li></ul></li><li><p>lr/sc 示例</p><p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">again:</span> <span class="hljs-built_in">lr</span>.d <span class="hljs-built_in">x10</span>,(<span class="hljs-built_in">x20</span>)  <span class="hljs-comment">//将x20寄存器指向内存地址的值load到x10寄存器中</span><br><span class="hljs-symbol">sc.d</span> <span class="hljs-built_in">x11</span>,<span class="hljs-built_in">x23</span>,(<span class="hljs-built_in">x20</span>)   <br><span class="hljs-comment">//首先检查x20寄存器指向内存地址的空间是否有保留标志，有，将x23寄存器的值store到x20指向的内存空间。并设置x11寄存器值为0.</span><br><span class="hljs-keyword">bne</span> <span class="hljs-built_in">x11</span>，<span class="hljs-built_in">x0</span>,again   <span class="hljs-comment">//如果x11寄存器中的值不为0，则跳回again</span><br><span class="hljs-symbol">addi</span> <span class="hljs-built_in">x23</span>,<span class="hljs-built_in">x10</span>,<span class="hljs-number">0</span>      <span class="hljs-comment">//完成x23寄存器的值和x20寄存器指向的内存地址的值的原子交换</span><br></code></pre></td></tr></table></figure></p></li></ul><h4 id="amoatomic-memory-operation">4.2.2 AMO（Atomic MemoryOperation）</h4><ul><li>使用前面介绍的lr/sc指令可以进行加解锁，执行原子操作。但这种实现起来较为复杂，尤其对于单变量的原子操作，使用这种方式的代价很大。</li><li>AMO即原子内存操作，AMO又分为几类，包括：<strong>原子交换指令、原子加法指令、原子逻辑指令和原子取大小值指令。</strong></li><li>（1）原子交换指令<ul><li><p>amoswap 指令格式如下所示</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dust"><span class="language-xml">amoswap.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br></code></pre></td></tr></table></figure></li><li><p>其伪代码如下所示。</p><ul><li>先将内存rs1地址处数据给到rd寄存器，之后再将rs2数据写入rs1地址处，实现rs2与内存中数据交换。</li><li>伪代码中两步应是原子的、不可分割的。</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">rd</span>=*rs1<br>*<span class="hljs-attribute">rs1</span>=rs2<br></code></pre></td></tr></table></figure></li></ul></li><li>（2）原子加法指令<ul><li><p>amoadd 指令格式如下所示</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dust"><span class="language-xml">amoadd.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br></code></pre></td></tr></table></figure></li><li><p>其伪代码如下所示。</p><ul><li>该指令返回rs1地址处内存原先值给rd寄存器了；后将rs2和内存中地址为rs1处的数据进行相加，并将相加结果写回内存地址为rs1处。</li><li>伪代码中两步应是原子的、不可分割的。</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">rd = <span class="hljs-strong">*rs1</span><br><span class="hljs-strong">*rs1 = *</span>rs1 + rs2<br></code></pre></td></tr></table></figure></li></ul></li><li>（3）原子逻辑操作指令<ul><li><p>一共有3条：原子与、原子或、原子异或。指令格式分别如下。</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dust"><span class="language-xml">amoand.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br><span class="language-xml">amoor.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br><span class="language-xml">amoxor.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br></code></pre></td></tr></table></figure></li><li><p>其伪代码如下所示。</p><ul><li>三个逻辑运算都是将rs1作为内存地址，将地址原数据返回给rd寄存器。后从内存中取出数据与rs2做逻辑运算，并将运算结果写回内存中。</li></ul><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-comment">//amoand</span><br>rd = *rs1<br><span class="hljs-comment">*rs1 = *rs1 &amp; rs2</span><br><span class="hljs-comment">//amoor</span><br>rd = *rs1<br><span class="hljs-comment">*rs1 = *rs1 | rs2</span><br><span class="hljs-comment">//amoxor</span><br>rd = *rs1<br><span class="hljs-comment">*rs1 = *rs1 ^ rs2</span><br></code></pre></td></tr></table></figure></li></ul></li><li>（4）原子取大小值指令<ul><li><p>其包括4条指令：原子有符号取大值指令、原子无符号取大值指令、原子有符号取小值指令、原子无符号取小值指令。指令格式如下。</p><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dust"><span class="language-xml"># 其中带u的为无符号，没有u的为有符号</span><br><span class="language-xml">amomax.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br><span class="language-xml">amomaxu.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br><span class="language-xml">amomin.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br><span class="language-xml">amominu.</span><span class="hljs-template-variable">&#123;w/d&#125;</span><span class="language-xml">.</span><span class="hljs-template-variable">&#123;aqrl&#125;</span><span class="language-xml"> rd,rs2,(rs1)</span><br></code></pre></td></tr></table></figure></li><li><p>其伪代码如下所示。</p><ul><li>四条大小值比较指令都是将rs1作为内存地址，将地址原数据返回给rd寄存器；后从内存中取出数据与rs2的值做大小值判断（包括有符号和无符号），将比较后的值返回给内存单元。</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">exts</span><span class="hljs-params">(a)</span></span><br>&#123;<br>    return 扩展符号(a)<br>&#125;<br><span class="hljs-comment">//amomax</span><br>rd = *rs1<br>*rs1 = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">exts</span>(*rs1),<span class="hljs-built_in">exts</span>(rs2))<br><span class="hljs-comment">//amomaxu</span><br>rd = *rs1<br>*rs1 = *rs1 = <span class="hljs-built_in">max</span>(*rs1,rs2)<br><span class="hljs-comment">//amomin</span><br>rd = *rs1<br>*rs1 = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">exts</span>(*rs1),<span class="hljs-built_in">exts</span>(rs2))<br><span class="hljs-comment">//amominu</span><br>rd = *rs1<br>*rs1 = *rs1 = <span class="hljs-built_in">min</span>(*rs1,rs2)<br></code></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>关于CPU</title>
    <link href="/2023/11/01/%E5%85%B3%E4%BA%8ECPU/"/>
    <url>/2023/11/01/%E5%85%B3%E4%BA%8ECPU/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li>《计算机组成与设计 第五版》</li><li>《手把手教你设计CPU RISC-V处理器》</li></ul></li></ul><hr><h2 id="1-CPU部分性能指标"><a href="#1-CPU部分性能指标" class="headerlink" title="1. CPU部分性能指标"></a>1. CPU部分性能指标</h2><h3 id="1-1-程序执行时间"><a href="#1-1-程序执行时间" class="headerlink" title="1.1 程序执行时间"></a>1.1 程序执行时间</h3><ul><li>程序的CPU执行时间 &#x3D; 程序占用CPU时钟周期数 * 时钟周期。<ul><li>所以提高程序响应时间可以通过减少程序执行所需的时钟周期数，或提高时钟频率。</li></ul></li><li>上式的程序占用CPU时钟周期数 &#x3D; 程序指令数 * 指令平均时钟周期数。<ul><li>其中指令平均时钟周期数是指执行每条指令所需要的时钟周期平均数，缩写为Cycles per Instruction，CPI。</li><li>因此程序占用时间 &#x3D; 指令数 * CPI * 时钟周期长度。</li></ul></li><li>算法、编程语言和编译器会影响指令数和CPI，而指令系统体系结构在此基础上还会影响时钟周期长度。</li></ul><h3 id="1-2-CPU-频率"><a href="#1-2-CPU-频率" class="headerlink" title="1.2 CPU 频率"></a>1.2 CPU 频率</h3><ul><li>主要包括主频、外频和倍频。<ul><li>主频：CPU内核工作的时钟频率。</li><li>外频：系统总线的工作频率，CPU与周边设备传输数据的频率。该频率越高，单位时间系统接收来自外设的数据越多。</li><li>倍频：其值 &#x3D; 主频&#x2F;外频。</li></ul></li></ul><h3 id="1-3-缓存容量和性能"><a href="#1-3-缓存容量和性能" class="headerlink" title="1.3 缓存容量和性能"></a>1.3 缓存容量和性能</h3><ul><li>有关于缓存的内容可见<a href="https://www.cnblogs.com/qianbinbin/category/2316464.html">这个文件夹</a>。</li></ul><h2 id="2-ISA-指令集体系结构"><a href="#2-ISA-指令集体系结构" class="headerlink" title="2. ISA - 指令集体系结构"></a>2. ISA - 指令集体系结构</h2><ul><li>ISA是一种规约，规定了如何使用硬件。<ul><li>它规定了包括：指令格式、操作种类、操作数类型、存储空间大小、编址方式、大小端以及寻址方式等。</li></ul></li></ul><h3 id="2-1-CISC-和-RISC"><a href="#2-1-CISC-和-RISC" class="headerlink" title="2.1 CISC 和 RISC"></a>2.1 CISC 和 RISC</h3><ul><li>主要分为CISC 和 RISC。<ul><li>由于CISC指令定义的指令只有20%经常被使用到，而那些不常用的指令使得CPU的设计变得极为复杂，增加成本。</li><li>RISC只包含那20%常用的指令，对于不常用的可以组合多条指令完成。</li></ul></li></ul><h3 id="2-2-32-64位架构"><a href="#2-2-32-64位架构" class="headerlink" title="2.2 32 &amp; 64位架构"></a>2.2 32 &amp; 64位架构</h3><ul><li>位数一般就是指通用寄存器的位宽，决定了寻址范围的大小，2^32&#x2F;2^64；决定了数据处理能力的强弱，一个周期处理32bit&#x2F;64bit的数据。</li><li>注意：<strong>指令集架构的位宽与指令长度无关。</strong></li></ul><h3 id="2-3-常见的指令集架构"><a href="#2-3-常见的指令集架构" class="headerlink" title="2.3 常见的指令集架构"></a>2.3 常见的指令集架构</h3><ul><li>x86：CISC指令集，之后发展的“微码化”可以实现一种近似RISC的形式。但是还是需要额外的硬件解码器。（Intel、AMD是主要的x86处理器芯片供应商）。</li><li>MIPS：RISC指令集。</li><li>ARM：RISC指令集。</li><li>RISC-V：免费开放架构，没有专利桎梏。</li></ul><h2 id="3-冯诺依曼-哈佛-结构"><a href="#3-冯诺依曼-哈佛-结构" class="headerlink" title="3. 冯诺依曼 &amp; 哈佛 结构"></a>3. 冯诺依曼 &amp; 哈佛 结构</h2><ul><li>两者区别<ul><li>冯诺依曼 将指令和数据放在一个存储器中，指令和数据宽度一致；哈佛结构 将指令和数据分开存储在两个存储器中，指令和数据宽度不一致。  </li><li>冯诺依曼的指令和数据共享一根总线，所以在执行操作时都需要先取指令后取数据（顺序串行）；而哈佛结构的两个存储器是分开的，有两根总线，可以在读取指令时对数据进行操作（并行），效率更高。</li></ul></li><li>在<a href="https://www.cnblogs.com/qianbinbin/p/17468356.html">这篇博客</a>中，可以看到在CPU内部，L1 Cache是有ICache和DCache，可以理解CPU内部为哈佛结构。<ul><li>在L2 Cache及更外面的Cache以及主存中均为指令和数据缓存在一起，可认为是冯诺依曼结构。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>计算机系统层次</title>
    <link href="/2023/10/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1/"/>
    <url>/2023/10/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://www.icourse163.org/learn/NJU-1001625001"class="uri">https://www.icourse163.org/learn/NJU-1001625001</a></li></ul></li></ul><h2 id="计算机系统层次">1. 计算机系统层次</h2><ul><li><p>软件程序的转换处理过程</p><ul><li>以C-源程序为例，在GCC+Linux平台中的处理如下：<ul><li>（1）首先输入源程序文件hello.c，经过<strong>预处理</strong>（使用cpp）得到hello.i文件，其仍为源程序。</li><li>（2）对hello.i文件进行<strong>编译</strong>，得到hello.s文件，其为汇编语言程序。</li><li>（3）将hello.s文件送入<strong>汇编器</strong>中，得到hello.o文件，其为可重定位目标程序（二进制，包括多条机器指令）。</li><li>（4）在程序中可能还有其它源程序参与，所以需要拿到其它源程序的.o文件，并进行<strong>链接</strong>，得到可执行目标程序（二进制）。</li></ul></li><li>上面介绍为计算机软件层实现的，从<strong>高级语言源程序-汇编语言源程序-机器语言目标程序</strong>的过程。</li><li>在计算机硬件层面，有<strong>指令译码器</strong>对机器语言的<strong>二进制指令进行译码</strong>，生成对应的控制信号来实现计算机的一些硬件操作。</li></ul></li><li><p>现代计算机系统层次如下图所示。</p><ul><li>其中语言处理系统包括：<ul><li>各种语言处理程序（如编译、汇编、链接）。</li><li>运行时的系统：如库函数，调试、优化等功能。</li></ul></li><li>其中操作系统包括人机交互界面、提供服务功能的内核例程。</li><li>其中指令集体系结构（ISA）可以认为是对计算机硬件设计的抽象，而所有的软件功能也都是建立在ISA之上。<ul><li>其中ISA相关的内容可以看<ahref="https://www.cnblogs.com/qianbinbin/p/17515912.html">这篇博客</a>。</li><li>计算机硬件需要满足ISA规定的功能。</li></ul></li></ul></li></ul><pre><code class=" mermaid">graph TBA(应用程序) --&gt; B(语言处理系统) --&gt; C(操作系统) --&gt; D(指令集体系结构) --&gt; E(计算机硬件)</code></pre><h2 id="可执行文件生成过程详解">2. 可执行文件生成过程详解</h2><h3 id="预处理">2.1 预处理</h3><ul><li><p>仍以C-源程序、GCC+Linux平台为例；预处理命令格式如下：</p><p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -E a.c -o a.i</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">或直接使用预处理命令：cpp</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">cpp a.c &gt; a.i</span><br></code></pre></td></tr></table></figure></p></li><li><p>预处理主要完成以下任务</p><ul><li><p>处理源文件中以 “#” 开头的预编译指令，包括：</p><ul><li>删除 “#define” 并展开所定义的宏。</li><li>处理所有条件预编译指令，如 “ #if”，“#ifdef”，“#endif” 等。</li><li>处理源文件中的“#include”，将头文件插入此处；如果头文件中也有#include，可以进行递归处理。</li><li>添加代码行号和文件名标识，方便编译时编译器产生调试用的行号信息等。</li><li>保留所有 “#pragma” 编译指令，在后面编译时，编译器需要使用。</li></ul></li><li><p>经过预处理后，得到的仍是源文件，只是不包含任何宏定义。</p></li><li><p>举例如下</p><p><img src="image-20231030201350657.png" style="zoom:50%;" /></p></li></ul></li></ul><h3 id="编译">2.2 编译</h3><ul><li><p>对预处理后得到的文件进行词法分析、语法分析、语义分析并优化，生成汇编代码文件。</p></li><li><p>编译命令格式如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -S a.i -o a.s</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">或直接使用编译命令 cc1</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">/users/.../cc1 a.i</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">如果将预处理和编译放在一起进行</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -S a.c -o a.s</span><br></code></pre></td></tr></table></figure></li><li><p>可以看到无论是预处理、编译还是后面的汇编，都可以使用gcc命令。</p><ul><li>gcc命令实际上是具体程序（如 ccp/cc1/as 等）的包装命令。</li><li>用户可以使用gcc命令，并加上特定选项来使用特定的程序。</li></ul></li></ul><h3 id="汇编">2.3 汇编</h3><ul><li><p>汇编指令和机器指令是一一对应的，前者是后者的符号表示，都是机器级指令。</p></li><li><p>汇编指令格式如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -c a.s -o a.o</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">或直接使用汇编命令as</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">as a.s -o a.o</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">可以使用下面命令直接完成三步</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -c a.c -o a.o</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="链接">2.4 链接</h3><ul><li><p>链接指令格式如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">其中myproc为链接后生成的可执行文件</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">gcc -static -o myproc main.o test.o</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">或直接采用链接命令ld</span><br><span class="hljs-meta prompt_">$</span><span class="language-bash">ld -static -o myproc main.o test.o</span><br></code></pre></td></tr></table></figure></li><li><p>链接操作步骤</p><ul><li>（1）确定符号引用关系，代码段符号、数据段符号相互关联起来。</li><li>（2）合并相关的.o文件，将相关的代码段和数据段分别合并在一起。</li><li>（3）在合并后，就可以确定每个符号的地址，如下图的P0,P1,A,B,C等。</li><li>（4）在指令中添入新的地址。</li><li>第（1）步为符号解析，后面三步称为重定位。</li></ul><p><img src="2.png" style="zoom:50%;" /></p></li><li><p>C语言程序举例</p><ul><li>下图为<strong>可重定位目标文件和可执行目标文件</strong>之间映射关系。<ul><li>注意：swap()函数中的temp变量为局部变量，其被分配在栈中，不会在过程外被引用，因此不是符号定义。</li><li>在链接过程中会将相同的节进行合并。并完成符号解析和重定位。</li><li>图中text节为代码节，data节为已初始化后的数据节，bss为未初始化的全局变量和局部静态变量。还有许多其它未介绍的节，可以网上查阅。<ul><li>注意：bss节中默认初始值为0，因此在磁盘并不需要占实际空间，只需要在节头表中声明此处需要多少长度的内存空间。</li><li>在写入虚拟内存时，需要为4个节分配存储空间，分别为text，data，bss 和rodata。</li><li>节头表包括了每个节的节名、偏移、大小、访问属性、对齐方式等信息。</li></ul></li></ul></li></ul><p><img src="image-20231030215107334.png" style="zoom:50%;" /></p><p><img src="3.png" alt="3" style="zoom:50%;" /></p><ul><li><p>下图为磁盘中的<strong>可执行目标文件和虚拟内存</strong>之间的映射关系。</p><ul><li>其中<strong>ELF</strong>为Linux下的<strong>目标文件格式</strong>，后面会进行详细介绍。<ul><li>ELF头包括了文件类型，大端/小端，机器类型，以及程序头表和节头表相关信息（偏移、大小、个数等）。<ul><li>对于可执行目标文件，ELF头需要给字段 e_entry执行程序时第一条指令的地址。而在可重定位文件中因为并不需要进行执行，所以该字段为0.</li></ul></li></ul></li><li>其中程序（段）头表中说明了每个段的属性，包括：可执行目标文件中的节与虚拟地址的映射关系、段的大小、在虚拟空间中的位置、对齐方式以及访问属性等。<ul><li>程序头表中有<strong>两个表项为可装入段</strong>(即：Type=LOAD)，完成向虚拟空间装入<strong>只读代码段以及读写数据段。</strong></li></ul></li><li>像前面介绍，在写入虚拟内存时，只需要为4个节分配存储空间。因此下图中可执行目标文件灰色部分的节不需要装入到存储空间。</li><li>另外，可执行目标文件比可重定位目标文件<strong>多了一个.init节</strong>，用于定义_init函数，该函数是用来进行执行目标文件时的初始化工作的。</li></ul><p><img src="4.png" alt="4" style="zoom:50%;" /></p></li></ul></li></ul><h3 id="目标文件">2.5 目标文件</h3><ul><li>三类目标文件<ul><li>可重定位目标文件 (.o)<ul><li>为汇编之后得到的文件，其代码和数据可以和其它可重定位文件合并为可执行文件。</li><li>每个.o文件的代码和数据地址都是从0开始。</li></ul></li><li>可执行目标文件（Linux默认为a.out，windows中为*.exe）<ul><li>包含代码和数据可以被直接映射到虚拟内存中被执行。</li><li>代码和数据的地址为虚拟内存空间中的地址。</li></ul></li><li>共享的目标文件（Linux中的*.so）<ul><li>特殊的可重定位目标文件，能够在运行时自动被装入到内存中并自动链接到某个存在相关调用的可执行目标文件中。</li><li>这种是<strong>动态的被链接</strong>，区别于前面添加多个相关的可重定位目标文件进行的<strong>静态链接</strong>。</li><li>更详细的会在后续动态链接处进行介绍。</li></ul></li></ul></li><li>目标文件格式<ul><li>DOS 操作系统：COM格式。<ul><li>仅包含代码和数据，且被加载到内存的固定位置，不采用虚拟地址。</li></ul></li><li>System V UNIX 早期版本：COFF格式。<ul><li>不仅包含代码和数据，还包含<strong>重定位信息、调试信息、符号表等</strong>。</li></ul></li><li>Windows：PE格式，COFF的变种。</li><li>Linux：ELF (Executable and Linkable Format) 格式，COFF的变种。</li></ul></li></ul><h2 id="elf格式">3. ELF格式</h2><ul><li><p>存在两种视图，包括链接视图(Linkable)和执行视图(Executable)。</p><ul><li><p>链接视图</p><ul><li>主要展示被链接的情况，按照相同特征划分为不同节。</li></ul></li><li><p>执行视图</p><ul><li>主要展示被执行的情况，将具有相同访问属性的节合并成段。</li><li>前面也有介绍，段的属性被包括在程序（段）头表中。</li></ul><p><img src="811006-20180503113716101-439702289.png" /></p></li></ul></li></ul><p>​</p>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>软件层</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Cache一致性</title>
    <link href="/2023/10/29/Cache%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    <url>/2023/10/29/Cache%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/136300660"class="uri">https://zhuanlan.zhihu.com/p/136300660</a></li><li><a href="https://zhuanlan.zhihu.com/p/515450647"class="uri">https://zhuanlan.zhihu.com/p/515450647</a></li></ul></li></ul><hr /><h2 id="cache-的-invalidate-clean">1. Cache 的 invalidate &amp;clean</h2><ul><li>invalidate<ul><li>将相应位置的cacheline状态置为无效，<strong>将validbit置为0</strong>. 并不需要清除相应位置的cacheline数据。</li><li>复位之后，需要将所有的cacheline的valid信号置为0，防止复位后，cache命中拿到错误未定义的数据。</li></ul></li><li>clean<ul><li>将<strong>dirty bit</strong>为1的cacheline写回主存中，同时拉低cacheline的dirtybit，通过这种方式可以将cache中的数据和主存中数据保持一致（针对写回策略）。</li></ul></li></ul><h2 id="cache-dma一致性">2. Cache &amp; DMA一致性</h2><ul><li>DMA &amp; Cache<ul><li>DMA相关内容可见<ahref="https://i.cnblogs.com/posts?cateId=2319426">这个专题</a>。DMA可以实现不经过CPU实现外设和存储器以及存储器和存储器的数据传输。</li><li><ahref="https://www.cnblogs.com/qianbinbin/p/17468440.html">这篇博客</a>中介绍Cache的位置为CPU Registers 和 主存之间数据交互的桥梁。</li><li>可能会出现如下情况：Cache采用写回策略，Cache中更改的数据暂未被写回到主存，但此时DMA已经将主存中旧的数据传输给外设接口；程序运行出现问题。</li></ul></li><li>Cache的总线监视技术<ul><li>为了解决上面Cache和DMA不一致的问题，可以在DMA通过总线获取数据时，先检查cache是否命中，如果命中的话，数据应该来自cache而不是主存。</li><li>可以通过cache的总线监视技术实现，cache控制器会监视总线上的每一条内存访问，检查是否命中，根据命中情况做下一步操作。<ul><li>DMA操作的是物理地址，cache若想监视DMA的访问地址，那么需要Cache也是按照物理地址进行查找的，所以选择PIPTCache结构。</li></ul></li><li>对于一些已经设计完成的硬件电路，并不支持总线监视技术，那么也可以通过其它方式避免DMA和Cache不一致的问题。</li></ul></li><li>No Cache<ul><li><ahref="https://www.cnblogs.com/qianbinbin/p/17491401.html">这篇博客</a>中有介绍DMA在主存中实现双缓冲用做主存到IO口/IO口到主存的数据传输，为了避免cache的影响，我们可以选择将这段内存映射为nocache。</li><li>这种方法很简单实用，但缺点是：如果偶尔使用DMA，但将缓冲区一段的内存设为nocache，导致CPU Register-主存 的性能损失。</li></ul></li><li>软件维护一致性<ul><li>为了避免NoCache带来的性能损失，可以选择映射仍采用cache的方式，根据DMA传输方向不同分情况讨论。<ul><li>DMA传输方向为：I/O -&gt; 内存(DMA Buffer)<ul><li>在DMA传输之前，可以invalidate DMA buffer段的cache。</li><li>在DMA传输完成之后，由于buffer对应段的cachelinevalid置为0，数据需要重新加载，并将valid重新置为1.这样CPU读cache中的数据就不会读到过时的数据了。</li></ul></li><li>DMA传输方向为：内存(DMA Buffer) -&gt; I/O<ul><li>在DMA传输前，可以clean DMA buffer段的cache。</li><li>将cache中dirty bit被拉高的cacheline写回主存中，这样在DMA传输时，就不会将主存中过时数据发送到I/O设备。</li></ul></li></ul></li><li>注意：在DMA传输没有完成期间，我们需要保证CPU不要访问DMABuffer。因为可能CPU读走的数据并不是最终完成DMA传输的数据，导致程序错误。</li></ul></li><li>DMA Buffer对齐<ul><li>实例可以看<ahref="https://zhuanlan.zhihu.com/p/109919756">这篇文章</a>。</li><li>简要概述一下文章中描述的情况，如下：<ul><li>若未对齐，那么变量temp和buffer在cacheline中的存放如下图所示。</li><li>现DMA进行外设-&gt;内存传输数据到buffer变量中。</li><li>但在传输过程中，DMA传输到buff[3]时，CPU对temp的进行改动；之后DMA传输到buff[50]时，由于其它操作可能需要替换掉temp所在cacheline，发现dirtybit被拉高，便需要将该行cacheline写回。这个过程都发生在DMA传输过程中。</li><li>从图中可以看到写回的时buffer[0]-buffer[59],直接覆盖掉DMA从外设传输过来的buffer值。</li><li>可以通过对齐DMAbuffer来解决这个问题，即让buffer变量不和其它数据公用一个cacheline。</li></ul><img src="3201119-20230811122740521-659669830.png" /></li></ul></li></ul><h2 id="icache-和-dcache-一致性">3. ICache 和 DCache 一致性</h2><ul><li><ahref="https://www.cnblogs.com/qianbinbin/p/17468356.html">这篇博客</a>中有介绍，在CPU的L1Cache会单独分为ICache和DCache。而L2和L3不会区分ICache和DCache。</li><li>ICache的歧义和别名<ul><li>歧义和别名在<ahref="https://www.cnblogs.com/qianbinbin/p/17470849.html">这篇博客</a>中有介绍。</li><li>歧义可以通过 Physical Tag解决，对于VIPT型Cache，仍然存在别名的问题。</li><li>考虑到ICache的Read Only特性，所以即使两个Cacheline上缓存一个物理地址上的数据也没有关系。</li></ul></li><li>不一致性的情况<ul><li>程序在执行过程中，指令一般不会修改，此时不会出现一致性问题。</li><li>但是对于一些特殊情况：self-modifyingcode，在执行时会修改自己的指令，它们修改指令的过程为：<ul><li>将需要修改的指令加载到dCache中。</li><li>修改成新指令，写回dCache。</li></ul></li><li>可能会出现的问题<ul><li>如果旧指令已经缓存在iCache中。那么对于程序执行来说依然会命中iCache。这不是我们想要的结果。</li><li>如果旧指令没有在iCache中，那么CPU会去主存中取指令数据，而如果dCache采用的是写回策略，那么指令会被写回到dCache，而不会写回主存，那么从主存中取出的指令也不是想要的。</li></ul></li></ul></li><li>不一致性的解决方案<ul><li>硬件维护<ul><li>硬件上让iCache和dCache之间通信。</li><li>每一次修改dCache数据时，去查一下iCache是否命中；如果命中，那么也更新一下iCache。</li><li>当加载指令时，先去查找iCache中是否命中，如果没有命中，再去dCache中查找。如果都没有命中再去查找主存。</li><li>但是self-modifyingcode是少数，为了解决少数的情况，却给硬件带来了很大的负担。</li></ul></li><li>软件维护<ul><li>可以通过下面的步骤维护一致性。<ul><li>（1）将需要修改的指令数据加载到dCache中。</li><li>（2）修改成新指令，写回dCache。</li><li>（3）cleandCache中修改的指令对应的cacheline，保证dCache中新指令写回主存。</li><li>（4）invalidiCache中修改的指令对应的cacheline，保证从主存中读取新指令。</li></ul></li></ul></li></ul></li></ul><h2 id="多核cache一致性">4. 多核Cache一致性</h2><ul><li>每个CPU之间都有一个L1Cache，如果为多核，需要考虑多核Cache之间的一致性。</li><li>不一致性的情况<ul><li>假设存在两个CPU，都有对应的L1Cache。首先两个CPU都读取了0x40地址数据，CPU从主存加载数据到对应的CacheLine中。</li><li>采用写回策略，CPU0写数据会更新其对应的L1_Cahce0，dirtybit被拉高。之后CPU1发现命中了L1_Cache1，将未被修改的值读出。导致数据读出错误。</li></ul></li><li>解决思路<ul><li>思路一：CPU0修改0x40的时候，除了更新CPU0的Cache之外，还应该通知CPU1的Cache更新其Cache0x40的数据。<br /></li><li>思路二：<ul><li>CPU0修改0x40的时候，除了更新CPU0的Cache之外，还可以通知CPU1的Cache将0x40地址所在cacheline置成invalid。保证CPU1读取数据时不会命中自己的Cache。</li><li>不命中CPU1的Cache之后，我们有两种选择保证读取到最新的数据。<ul><li><ol type="a"><li>从CPU0的私有cache中返回0x40的数据给CPU1；</li></ol></li><li><ol start="2" type="a"><li>CPU0发出clear信号后，将cache0 0x40的数据写回主存，CPU1cache置为invalid，从主存读取最新的数据。</li></ol></li></ul></li></ul></li></ul></li><li>解决方法<ul><li>现在几乎不会使用软件维护一致性，因为成本过高，维护一致性带来的性能损失会抵消掉一部分cache带来的性能提升。</li><li>目前主要采用硬件维护，这里介绍Bus Snooping Protocol和MESIProtocol。</li><li>Bus Snooping Protocol<ul><li>实现思路<ul><li>总线监控协议，当CPU0修改自己私有的Cache时，硬件就会广播通知到总线上其它的CPU。</li><li>对于每个CPU来说，会有特殊的硬件去监听广播事件，并检查是否有相同地址的数据被缓存在自己的CPU上。</li><li>如果其它CPU缓存上存在相同地址的数据，那么也需要对应更新cacheline。</li></ul></li><li>存在问题<ul><li>总线需要每时每刻监听总线上的一切活动，一定程度上增加了总线负载和读写延迟。</li></ul></li></ul></li><li>MESI Protocol<ul><li>主要解决针对Bus Snooping Protocol存在的问题。</li><li>MESI：主要是指四种状态，Modified、Exclusive、Shared、Invalid。</li><li>举例，继续上面的例子。<ul><li>当CPU0从主存中读取0x40的数据，将数据加载到cache0中。此时CPU1的cache1中没有该地址数据，所以可以在cache0中标记该cacheline为<strong>Exclusive</strong>状态。表示该cacheline的数据是某一个CPU独占的。</li><li>当CPU1也想读0x40的数据，CPU1就会发送消息给其它CPU，发现cache0中存在该数据，那么数据将会从cache0给到cache1.cacheline的状态变为<strong>Shared</strong>。表示该数据在多个CPU的cache中被缓存，且与主存数据保持一致。</li><li>当CPU0继续修改0x40地址的数据，发现该地址cacheline为shared状态，CPU0会发送<strong>Invalid</strong>信息给到其它CPU。<ul><li>CPU1接收到invalid信号，将对应地址(0x40)cache line置为invalid。</li><li>CPU0收到CPU1更改invalid状态的信息之后，修改0x40所在的cacheline中的数据，并更新cache line的状态为<strong>Modified</strong>。</li><li>Modified表示该cacheline数据是某一个CPU私有的，且与主存中的数据不一致，表示被修改。</li></ul></li><li>如果CPU0还想要修改cache0 0x40的数据，并发现cacheline的状态为Modified；此时CPU0不需要向其它CPU发送消息，直接更新数据就可以。因为当前cacheline数据是其CPU独有的。</li><li>如果当前cache line需要被替换，发现cacheline的状态是Modified，数据会先被写回主存中。</li></ul></li><li>上面介绍的例子中，如果cacheline的状态是Modified/Exclusive状态，修改其数据并不需要通知其它CPU，这在一定程度上减轻了带宽的压力。</li></ul></li><li>MESI Protocol Messages<ul><li>CPU、L1 Cache之间的数据和状态是通过发送message进行同步的。</li><li>主要包括以下几种Messages：<ul><li>Read: CPU需要读取某个地址的数据，发送Read Message。</li><li>Read Response: 读回复，并且返回需要读取的数据。</li><li>Invalidate: 要求其他CPU invalid对应地址的cache line。</li><li>Invalidate Acknowledge: 回复 发起invalidate的CPU，表明对应的cacheline已经被invalidate。</li><li>Read Invalidate: Read + Invalidate消息的组合。</li><li>Writeback: 该消息包含从Cache Line要回写到主存的地址和数据。</li></ul></li><li>更多关于MESI协议相关内容可见<ahref="https://www.cnblogs.com/qianbinbin/p/17731460.html">这篇博客</a>.</li></ul></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>TLB</title>
    <link href="/2023/10/29/TLB/"/>
    <url>/2023/10/29/TLB/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/108425561"class="uri">https://zhuanlan.zhihu.com/p/108425561</a></li></ul></li></ul><hr /><h2 id="tlb由来">1. TLB由来</h2><ul><li>在<ahref="https://www.cnblogs.com/qianbinbin/p/17466384.html">这篇博客</a>中有简单介绍。</li><li>MMU根据页表，将虚拟地址映射得到对应的物理地址。<ul><li>页表在64bit系统中，常见为3-5级，以4级为例，分别有PGD。</li><li>硬件上有一个<strong>页表基地址寄存器</strong>，存放着PGD页表的首地址；之后根据虚拟地址中PGDindex查找到对应的PUD页表的首地址，依次类推，最后找到PTE中存放的物理地址。示意图在<ahref="https://zhuanlan.zhihu.com/p/108425561">这篇文章</a>中，结合看更清晰。</li></ul></li><li>上面所描述的查找过程十分费时，影响性能，考虑加一块缓存，提高速度。于是就出现了TLB。<ul><li>TLB本质上是一块高速缓存，在虚拟地址到物理地址转换时，首先查找TLB，是否命中，如果命中直接得到物理地址。如果未命中，仍需要一级一级查找页表获取物理地址，并需要将虚拟地址和物理地址的映射关系缓存到TLB中。</li></ul></li></ul><h2 id="tlb-的歧义别名">2. TLB 的歧义&amp;别名</h2><ul><li>由于TLB用途就是根据虚拟地址查找cache，所以TLB必定是VIVT。<ahref="https://www.cnblogs.com/qianbinbin/p/17470849.html">这篇博客</a>中有介绍VIVT存在<strong>歧义和别名</strong>的问题。</li></ul><h3 id="tlb-特殊处理">2.1 TLB 特殊处理</h3><ul><li>TLB 有些不同于前面学习的Cache，在<ahref="https://www.cnblogs.com/qianbinbin/p/17466384.html">这篇博客</a>中，可以看到虚拟地址映射单位为Page，一般Page大小取4KB，所以TLB不需要存储虚拟地址的低12bit，在最后得到PPN的值后直接拼接低12bits即可。</li><li>另外，命中cache之后，cache line中的数据即pageindex，所以都会被取出，不需要offset域。</li><li>index域是否存在取决于是否为全相联缓存。</li></ul><h3 id="别名">2.2 别名</h3><ul><li>VIVT 数据Cache出现别名的主要原因在<ahref="https://www.cnblogs.com/qianbinbin/p/17470849.html">这篇博客</a>。根本在于存在一个修改<strong>地址-数据映射关系</strong>，且未被同步。</li><li>TLB虽然是VIVT，但是由于其不存在修改<strong>虚拟地址-物理地址映射关系</strong>，那么就不会出现别名情况。</li></ul><h3 id="歧义">2.3 歧义</h3><ul><li>VIVT出现歧义的主要原因在于不同进程中，相同虚拟地址可能对应着不同的物理地址。</li><li>解决方法：与VIVT 数据Cache 相同，采用切换进程时flushTLB，将整个TLB置为无效；但会导致性能损失。</li></ul><h3 id="如何尽量避免flush-tlb">2.4 如何尽量避免flush TLB</h3><ul><li>前面介绍，TLB存在歧义问题主要是不同进程的相同虚拟地址对应不同物理地址，那么如果可以<strong>区分不同进程的TLB表项</strong>就可以避免flushTLB。<br /></li><li>上面的想法可以通过每行cacheline扩展几bit作为<strong>分辨进程ID</strong>（ASID:Address SpaceID），在判断TLB是否命中时，除了比较tag，还需要比较ASID，选择当前进程匹配的ASID的cacheline进行操作。</li><li>ASID的管理<ul><li>需要注意：<strong>ASID和进程ID并不是一个</strong>，进程ID取值范围很大，但ASID一般为8/16bit，只能区分256/65536个进程。所以ASID和进程ID不可能一一对应。</li><li>每创建一个新进程时，就会为之分配一个ASID，当所有的ASID都分配完了，就会flushTLB，之后重新分配。</li><li>ASID一方面需要放在TLB Cacheline中，另一方面可以将其放在前面介绍的页表基地址寄存器中拓展若干bit；在查TLB是否命中时，比较tag，以及这两部分的ASID是否相等。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Cache-虚拟地址&amp;物理地址</title>
    <link href="/2023/10/29/Cache-%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80&amp;%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80/"/>
    <url>/2023/10/29/Cache-%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80&amp;%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/107096130"class="uri">https://zhuanlan.zhihu.com/p/107096130</a></li></ul></li></ul><hr /><h2 id="vivtvirtually-indexed-virtually-tagged">1. VIVT（VirtuallyIndexed Virtually Tagged）</h2><ul><li>虚拟高速缓存：以虚拟地址作为查找对象。</li><li>首先虚拟地址给cache，如果命中，则返回数据给cpu，如果未命中，则将虚拟地址通过MMU转化为物理地址，根据物理地址从主存中读取数据。</li><li>优点<ul><li>不需要在查找cache过程将虚拟地址翻译成物理地址，节省了MMU转换的时间，提高访问cache的访问速度。</li></ul></li><li>缺点<ul><li>引入软件使用上的问题，歧义（ambiguity）和别名（alias）。</li></ul></li></ul><h2 id="歧义">2. 歧义</h2><ul><li>歧义是指数据在cache中有相同的tag和index。</li><li>发生情况：<strong>不同进程，相同的虚拟地址映射不同的物理地址。</strong><ul><li>可能出现A进程地址a映射的数据为b，而B进程地址a映射的数据为c，当A进程运行时，访问地址a会将数据b加载到cache上，而进程B运行时，访问地址a时命中了并将数据b返回给CPU，但是实际上B进程应该把数据c给CPU。</li></ul></li><li>解决方法：切换进程，flush cache，主要有两种。<ul><li>使主存储器有效：首先将主存置为有效，将cacheline上已经修改的数据写回主存上，避免修改的数据丢失。</li><li>使高速缓存无效：首先将cacheline都置为无效，保证切换时不会有进程误命中上一进程的数据。</li></ul></li><li>所以对于VIVT来说，每次进程切换时，都可能出现大量的cache缺失，且只要切换进程就需要flushcache，导致性能的缺失。</li></ul><h2 id="别名">3. 别名</h2><ul><li>发生情况：不同虚拟地址映射到相同物理地址。<ul><li>可能出现物理地址A对应的虚拟地址为B和C，index值B&lt;C,那么当程序想要修改物理地址A对应的数据时，采用写回策略，对B进行修改，且修改的值没有同步到主存中，当程序想要访问虚拟地址C时，命中，但是取出的数据是未修改的。</li></ul></li><li>解决方法<ul><li>（1）采用nocache映射，不通过cache映射，CPU直接去主存读写数据。既适用于不同进程共享数据也适用于相同进程共享数据。</li><li>（2）不同进程共享数据，可以选择在进程切换时，flushcache，（主要因为存在一个向主存写数据的过程）。</li><li>（3）同一进程共享数据，保证虚拟地址cache大小对齐，保证每次虚拟地址都会找到同一个cacheline，下面有更详细的描述。</li></ul></li></ul><h2 id="piptphysically-indexed-physically-tagged">4. PIPT（PhysicallyIndexed Physically Tagged)</h2><ul><li>物理高速缓存：为了解决VIVT歧义和别名的问题，tag和index都取自物理地址，对于物理地址来说tag和index都是唯一的。</li><li>实现过程<ul><li>CPU发出的虚拟地址首先经过MMU转化为物理地址，给到cache控制器观察是否命中。如果未命中，将去主存中根据物理地址取出数据。</li></ul></li><li>缺点<ul><li>硬件设计较VIVT要复杂很多，需要等待MMU转换之后才可以查cache。</li><li>为了加快MMU转换速度，硬件上也会加一块TLB，虚拟地址和物理地址转换可以<ahref="https://www.cnblogs.com/qianbinbin/p/17466384.html">这篇博客</a>。</li><li>很多CPU都使用PIPT高速缓存。</li></ul></li></ul><h2 id="viptvirtually-indexed-physically-tagged">5. VIPT（VirtuallyIndexed Physically Tagged）</h2><ul><li>物理标记的虚拟高速缓存</li><li>使用虚拟index查找cacheline，与此同时，将虚拟地址给MMU转换为物理地址。MMU转换完之后cache也查找结束了，此时比对物理tag是否相同，以判断是否命中cache。</li><li>不会存在歧义<ul><li>关键在于 VIPT的tag使用的是物理地址的PFN，是唯一的。</li></ul></li><li>不会存在别名（特定情况下）<ul><li>对于大部分系统来说，虚拟地址和物理地址之间的映射最小是以页为单位，在<ahref="https://www.cnblogs.com/qianbinbin/p/17466384.html">这篇博客</a>中有介绍，页addr[11:0]内的内容无论是物理地址还是虚拟地址都是相同的。</li><li>所以对于直接映射高速缓存，如果cache的大小小于等于4KB，那么意味着虚拟地址和物理地址的index是一样的，此时VIPT和PIPT是相同的。</li><li>对于多路组相连高速缓存，每一组大小小于等于4KB，使用虚拟地址（此时等于物理地址）来做index寻址，并选择物理地址的tag来选择命中哪路的cacheline。</li></ul></li><li>别名问题<ul><li>若cache的大小大于4KB，还是会出现别名问题。</li><li>目的：避免相同物理地址的数据被加载到不同cacheline中。<ul><li>解决方法：相同物理地址数据对应的虚拟地址满足cache大小对齐。</li><li>举例：cache大小8KB = 2^13，cache line大小为256B =2^8，那么虚拟地址应该是下表几种情况，这样才会都找到第4行cacheline，不会出现别名的情况。</li><li>Linux实现中，采用该方法解决的别名问题。<style>.center {width: auto;display: table;margin-left: auto;margin-right: auto;}</style></li></ul></li></ul></li></ul><div class="center"><table><thead><tr class="header"><th>address</th></tr></thead><tbody><tr class="odd"><td>0_00100_0000_0000</td></tr><tr class="even"><td>1_00100_0000_0000</td></tr><tr class="odd"><td>10_00100_0000_0000</td></tr><tr class="even"><td>...</td></tr></tbody></table></div><ul><li>对于L1Cache的ICache，如果使用VIPT，虽然存在别名问题，但是考虑其为<strong>只读</strong>，所以即使多个虚拟地址对应一个物理地址也没有关系。</li></ul><h2 id="不存在的pivt高速缓存">6. 不存在的PIVT高速缓存</h2><ul><li>没有任何优点，首先需要通过MMU转换，消耗时间。还存在歧义和别名的问题。</li></ul><h2 id="总结">7. 总结</h2><ul><li>VIVT几乎没有人使用，软件维护成本过高。</li><li>对于多路组相连高速缓存的一路大小小于等于4KB，采用VIPT。</li><li>对于一路大于4KB的，一般采用PIPT，VIPT也可以，但是还是需要特殊处理一下别名问题。</li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Cache-分配策略&amp;更新策略</title>
    <link href="/2023/10/29/Cache-%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5&amp;%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5/"/>
    <url>/2023/10/29/Cache-%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5&amp;%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/102293437"class="uri">https://zhuanlan.zhihu.com/p/102293437</a></li><li>《计算机组成与设计 第五版》</li></ul></li></ul><hr /><h2 id="分配策略">1. 分配策略</h2><ul><li>分配策略是指什么情况需要为数据分配cache line。</li><li>读分配<ul><li>当CPU读数据时，cache缺失，分配一个cacheline来缓存从主存中取出的数据。</li></ul></li><li>写分配<ul><li>场景：CPU写数据时，cache缺失。</li><li>当不支持写分配时，写指令直接更新主存的数据。例如：对某一页内存进行初始化操作（全部写0），此时就没必要将对应数据写入cache中。</li><li>支持写分配时，会首先将主存中的数据加载到cacheline中，（变成命中），然后更新cache line的数据/主存的数据。</li></ul></li></ul><h2 id="更新策略">2. 更新策略</h2><ul><li>更新策略是指当cache命中时，写操作如何更新数据。</li><li>写直通（Write Through）<ul><li>例如，CPU执行store指令，且cache命中，首先更新cache中的数据，并更新主存中的数据。cache和主存的数据保持一致。</li><li>但是<strong>性能不佳</strong>，因为每次写操作都会引起写主存的操作，这个延时是比较大的，至少100个处理器时钟周期，大大降低处理器性能。</li><li>上面描述情况的解决方案是：<strong>write buffer</strong><ul><li>数据写入cache的同时也写入写缓冲中，之后处理器继续执行。</li><li>写缓冲不断向主存中写入数据，如果写缓冲满了，那么处理器必须停顿流水线直到写缓冲中出现空闲表项。<ul><li>我认为有点类似乒乓操作。</li></ul></li><li>如果主存写操作的速率小于处理器产生写操作的速率，那么多大容量的缓冲都没用，都会很快就满了。</li><li>即使处理器产生写操作的写速率小于主存写操作速率，也可能会产生停顿，例如出现写burst传输时，此时可以增加写缓冲容量解决。</li></ul></li></ul></li><li>写回（Write Back）<ul><li>仍是CPU执行store指令，且cache命中，我们只更新cache中的数据，而不立即写入主存，此时cache和主存的数据不一致。</li><li><strong>cache line有1个bit（dirtybit）用于记录数据是否被修改过。</strong></li><li>当cache中的数据要被替换（如：出现写失效），才会写回主存中。</li><li>需要实现一个<strong>write-back buffer</strong>。<ul><li>在出现写失效时，需要根据dirty bit判断是否要将cacheline中的数据写回到主存中。</li><li>在主存读取需要填充到cache中的数据时，将cacheline中的数据写入write-back buffer中。</li><li>之后再由buffer写入主存中。</li></ul></li></ul></li><li>写回 &amp; 写直通<ul><li>写直通的写操作可以在一个周期内完成，读取标签的同时将数据写入对应的数据块。<ul><li>如果tag匹配，那么完成写操作，处理器继续执行。</li><li>如果tag不匹配，那么产生写失效，将主存中对应地址的数据取出送到cache中。</li></ul></li><li>写回的写操作至少需要两个周期去处理：第一个周期用于判断tag是否命中，若命中则第二个周期进行cache写操作。<ul><li>不能一个周期就完成的原因：如果在第一个周期就将数据写入，如果tag没有命中，会导致cacheline原有数据未来得及写回主存中，导致数据被破坏。</li><li>也可以像写直通一样实现一个<strong>store buffer</strong>。<ul><li>第一个周期，将数据写入storebuffer中，同时查找cache，判断是否命中。</li><li>如果命中，在下一个无用的cache访问周期将新数据从buffer中写入cache。</li></ul></li></ul></li></ul></li></ul><h2 id="实例">3. 实例</h2><ul><li>具体内容可以看<ahref="https://zhuanlan.zhihu.com/p/102293437">这篇文章</a>中的实例。</li><li>这里只列出我觉得需要特殊注意的地方<ul><li>当发现cache缺失时，会出现CPU从主存中取数据给cacheline的情况，此时需要注意dirty bit是否被拉高。<ul><li>如果该bit被拉高，那么cache的数据不能直接覆盖，说明这个数据对应的地址之前发生过写回操作，并没有同步到主存中，如果直接覆盖则会丢失这部分的数据。</li><li>将被替换这部分数据写回至主存中。</li><li>将主存中0x28地址（cacheline地址对齐，这里应该要被8整除）开始的8个数据写入cacheline中，并清除掉dirty bit，将offset找到的数据返回给CPU。</li></ul></li></ul></li></ul><h2 id="cache-性能评估">4. Cache 性能评估</h2><ul><li>$ CPU时间 = (CPU执行的时钟周期数 + 等待存储访问的时钟周期数) *时钟周期 $</li><li>假设等待存储访问的时钟周期数主要来自于cache引起的，下面根据读和写分开讨论。<ul><li>读操作带来的停顿周期数 只由读失效带来。 <spanclass="math display">\[读操作带来的停顿周期数=\frac{读操作数目}{程序}*\frac{读失效次数}{指令数目}*读失效代价\]</span><br /></li><li>写操作带来的停顿周期数<ul><li>写直通策略<ul><li>有两个停顿的来源，写失效和写缓冲停顿。后者为buffer满时仍进行写操作引发的停顿。<span class="math display">\[写操作带来的停顿周期数 =\frac{写操作数目}{程序}*\frac{写失效次数}{指令数目}*写失效代价+写缓冲满时的停顿周期\]</span></li></ul></li><li>写回策略<ul><li>停顿主要来源于cache line要被替换，并需要将原数据写回主存中。</li></ul></li></ul></li></ul></li><li>前面介绍是未命中时对性能的影响，但是除了失效率，还有命中时间也会对性能有很大的影响。<ul><li>举例：增大Cache的容量（主要是Cacheline的个数），更大的Cache需要更久的命中时间。这个命中时间可以算在CPU执行的时钟周期数上。</li><li>定义 平均存储访问时间(AMAT) 将Cache的命中时间也考虑在内，公式如下。<span class="math display">\[AMAT = 命中时间+失效率*失效代价\]</span></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Cache-直接映射缓存&amp;多路组连缓存</title>
    <link href="/2023/10/29/Cache-%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E7%BC%93%E5%AD%98&amp;%E5%A4%9A%E8%B7%AF%E7%BB%84%E8%BF%9E%E7%BC%93%E5%AD%98/"/>
    <url>/2023/10/29/Cache-%E7%9B%B4%E6%8E%A5%E6%98%A0%E5%B0%84%E7%BC%93%E5%AD%98&amp;%E5%A4%9A%E8%B7%AF%E7%BB%84%E8%BF%9E%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/102293437"class="uri">https://zhuanlan.zhihu.com/p/102293437</a></li><li>公众号：老秦谈芯</li><li>《计算机组成与设计 第五版》 ***</li></ul></li></ul><h2 id="cache-line">1. Cache line</h2><ul><li>cachesize：这里只考虑cache可以缓存最大<strong>数据</strong>的大小。这里忽略了tag和validbit的占用。</li><li>将cache均分相等的块，每一块称为cacheline，现在的硬件设计中，一般cache line的大小为4-128字节，cacheline做的太小会导致tag资源占用过大。</li><li><strong>cache line 是 cache 和主存之间数据传输的最小单位。</strong><ul><li>考虑到程序的空间局部性：即一个数据被访问了，那么它周围的数据在之后也有可能被访问。所以cache会选择连续一段数据公用一个tag，一起被传输。</li><li>在cache缺失时，即使CPU只需要从主存中读1个字节的数据出来，但是还是会直接load出8（该值为设定的cacheline大小）个字节填充整个cache line。</li></ul></li><li>Cache line size 的选择<ul><li>size指的是offset的大小，也就是Cache line的容量。</li><li>size增大，失效率一般会下降（更大程度的挖掘空间局部性）。</li><li>但是当Cache linesize占cache容量比例增加到一定程度，失效率会随之上升。原因如下：<ul><li>上面所描述的情况会导致Cache中可存放的cacheline数变少了，会导致数据经常被挤走。</li><li>cacheline的size不断增大，导致各字之间的空间局部性也会降低，失效率的收益不断减小。</li><li>失效损失增大，失效损失主要指从主存中读取数据并加载到cache的时间，size不断增大，导致传输时间也不断增大。</li></ul></li></ul></li></ul><h2 id="cache控制器怎么确定是否命中">2. Cache控制器怎么确定是否命中</h2><ul><li>首先假设cache 大小为64Bytes，cacheline大小为8Bytes。假设CPU想从地址为0x0654地址取一个字节数据。</li><li>考虑cacheline大小为8Bytes，使用地址低3bit来寻址其中的一个字节。(offset[2:0])</li><li>计算可得有8个cacheline，可以使用3bit地址来寻址是哪个cacheline。(index[5:3])</li><li>对于一个地址，即使确定了[5：3]bit，也不能就确信找到了正确的地址，还有更高位数信息。<ul><li>cache将高位信息用tag表示，tag、index、offset可以确定唯一的那个地址。</li></ul></li><li>检查是否命中：首先根据index找到cacheline，然后将cache的tag与地址的tag比对，如果相等，说明命中，如果不等，说明缺失。</li></ul><p><img src="3201119-20230609140440924-1848801620.png" /></p><ul><li>valid bit<ul><li>tag 前面还加了一位validbit，首先判断该位，判断缓存中的数据是否有效，若无效不用判断是否命中，直接缺失。</li><li>目的：考虑一些情况如：处理器刚启动时，cache中没有有效数据，对比是无用的。以及运行过程中，cache的一些cacheline可能还是空的，对比也是无用的。</li></ul></li><li>Cache 失效的处理<ul><li>这里以指令Cache失效为例。<ul><li>对于按序处理器，Cache失效，需要停顿流水线等待内存返回数据。<ul><li>对于乱序处理器，Cache失效，在等待cache失效处理时允许继续执行指令，更为复杂，这里暂不讨论。</li></ul></li><li>将PC值-4发送给内存。<ul><li>考虑到程序计数器是在执行的第一个时钟周期递增的，所以引发指令Cache失效的指令地址等于当前PC-4。</li></ul></li><li>对主存进行读操作，等待主存完成本次访问。</li><li>写Cacheline，将内存获取的数据写入，将高位填充到tag字段，将有效位拉高。</li><li>重启指令执行，重新取指，此次取指将会在指令cache中命中。</li></ul></li><li>数据Cache控制本质和上面相同，失效也需要短暂的暂停处理器，直到内存返回数据给Cache。</li></ul></li></ul><h2 id="直接映射缓存的优缺点">3. 直接映射缓存的优缺点</h2><ul><li>优点：硬件设计更简单、成本低。</li><li>缺点：cache thrashing（cache 颠簸）<ul><li>与上面假设相同，此时cpu想依次访问0x00，0x40，0x80地址的数据，这三个对应的index和offset都是一个，唯一区别是tag值。</li><li>访问0x00时，cache缺失，cpu从主存中load出8个字节大小的数据填充cacheline。</li><li>访问0x40时，索引到第0行cacheline，但这里存的是0x00对应的数据，仍缺失，再加载0x40地址的数据。</li><li>依次类推，0x80也要经过刚才两步：缺失+从主存中load。</li><li>这样cache对性能没什么提升。</li></ul></li><li>为了解决这个问题，引入了多路组相连缓存。</li></ul><h2 id="两路组相连缓存">4. 两路组相连缓存</h2><ul><li>假设cache 大小为64Bytes，cacheline大小为8Bytes。假设CPU想从地址为0x0654地址取一个字节数据。<ul><li>一共有8个cache line，将一路改成两路4个cache line。</li><li>offset依然是3bit，index只需要2bit即可。</li><li>找到某行index，对应两个cache line。然后将两个cacheline对应的tag与地址部分的tag进行对比。</li></ul></li><li>下图中，Tag的比较和DataSRAM的数据读取是并行的，可以增加cache读取速度。<ul><li>也可以串行，先比较Tag，再根据Tag比较结果去访问Data SRAM。</li></ul></li></ul><p><img src="3201119-20230807213451864-968491639.png" /></p><ul><li>缺点<ul><li>硬件成本更高，每次比较tag要比较多个cacheline对应的tag。</li></ul></li><li>优点<ul><li>可以降低cache颠簸可能性。前面提到的问题，0x00和0x40可以被加载到不同的路中。</li></ul></li></ul><h2 id="全相连缓存">5. 全相连缓存</h2><ul><li>取消index信号，每个cacheline占一个way。其实就相当于不考虑offset的3bit，其余地址一个一个放在表中的一条一条上，在这个表里挨个查，显而易见只适合小容量的cache。</li><li>此时查找是否命中，需要将地址的tag与所有组的tag进行比较。</li><li>因为不存在index，任意数据可以存在任意位置，可以最大程度降低cache的颠簸性。</li><li>硬件成本最高。</li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>关于Cache</title>
    <link href="/2023/10/29/%E5%85%B3%E4%BA%8ECache/"/>
    <url>/2023/10/29/%E5%85%B3%E4%BA%8ECache/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/102293437"class="uri">https://zhuanlan.zhihu.com/p/102293437</a></li><li><a href="https://zhuanlan.zhihu.com/p/102326184"class="uri">https://zhuanlan.zhihu.com/p/102326184</a></li><li>公众号：老秦谈芯</li></ul></li></ul><hr /><ul><li>后续有时间的情况下，可以阅读《计算机组成与设计-硬件软件接口》第五章的内容，对写的博客进行补充。</li></ul><hr /><h2 id="为什么需要cache">1. 为什么需要Cache</h2><ul><li>运行一个进程的步骤（假设为一个变量a加1）<ul><li>首先从磁盘（辅存）中读出可执行程序，并将其load到主存储器中。</li><li>CPU从主存储器中读出地址为A的数据发到CPU的通用寄存器中。</li><li>将通用寄存器的值加1.</li><li>CPU再将通用寄存器的值写给主存储器。</li></ul></li><li>上面的步骤中，第三步的速度很快，但是第二步和第四步，与主存的交互很慢。为了解决这个问题，使用一块速度极快但是容量小的存储设备：cachemeomory。</li></ul><p><img src="3201119-20230609101424628-456798622.png" /></p><ul><li>将Cache放在CPU和主存之间，作为主存数据的缓存，当CPU想从主存中取数据会首先检查Cache中是否有对应地址的数据，如果有的话就可以直接取出给CPU使用。</li></ul><h2 id="多级cache存储结构">2. 多级Cache存储结构</h2><ul><li>Cache不可避免的需要在容量和速度之间进行平衡，但是即使多级Cache的速度仍比主存要快的多.</li><li>以Cortex-A53为例，三级Cache分布如下<ul><li>每个CPU都有一个L1 Cache，L1Cache会分为单独的ICache（指令）和DCache（数据）。<ul><li>ICache和DCache本质是一样的，L1 Cache单独分开的原因：<ul><li>CPU执行时，可以同时从两个Cache中获取指令和数据，做到硬件上的并行，提升性能。</li><li>DCache不仅需要考虑读出还要考虑写入的问题；而ICache只会被读取。分开两个电路设计，为了更快！</li></ul></li><li>L1Cache是最接近处理器的，要求其与CPU有近似的速度，也就注定了其容量不能太大，一般使用SRAM实现。</li><li>L1Cache中，ICache和DCache的大小一般32-64KB，2-4个时钟周期访问时间。</li></ul></li><li>一个Cluster内所有的CPU都共享一个L2 Cache。<ul><li>L2Cache是指令和数据共享，速度可以比CPU慢一些，主要功能是尽量保存更多的内容。</li><li>一般也是SRAM实现，大小为256KB-2MB，10-20个时钟周期的访问时间。<ul><li>虽然与L1一样都是SRAM实现，但是L1的SRAM设计是为了速度进行优化，采用更复杂更大更多的晶体管，因此成本和功耗都增加了不少。</li></ul></li></ul></li><li>所有的Cluster之间共享L3 Cache。而L3 Cache通过总线与主存相连。<ul><li>在一些系统设计中，L3 cache及更高级采用的是DRAM设计，成本更低。</li><li>L3 Cache一般大小为8-80MB，20-50个时钟周期的访问时间。</li></ul></li></ul></li><li>注意：上面描述的多个cluster就有多个二级缓存，那么就牵扯到<strong>缓存一致性</strong>的问题，后面会介绍。</li></ul><h2 id="多级cache之间的配合">3. 多级Cache之间的配合</h2><ul><li>inclusive cache（一个地址的数据可以存在多级缓存中）<ul><li>CPU想获取主存某地址的数据时，首先先访问L1Cache，看是否命中，如果命中直接返回数据给GPU。</li><li>如果L1 Cache缺失，则会在L2Cache中继续寻找，如果找到，那么会把数据返回给L1和CPU.(返回给L1是为了下次可以在L1的时候就命中)。</li><li>同理，L2找不到去找L3，找到返回L1,L2，CPU。</li><li>如果L3也缺失，CPU只能去主存储器中找数据，找到返回给L1,L2,L3,CPU。</li></ul></li><li>exclusive cache：某一地址的数据只能存在于多级Cache中的一级。</li></ul><h2 id="cache对代码的影响">4. Cache对代码的影响</h2><ul><li>首先看两端代码片段 <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int arr[<span class="hljs-number">10</span>][<span class="hljs-number">128</span>]<span class="hljs-comment">;</span><br><br>for (i <span class="hljs-operator">=</span> <span class="hljs-number">0</span><span class="hljs-comment">; i &lt; 10; i++)</span><br>        for (j <span class="hljs-operator">=</span> <span class="hljs-number">0</span><span class="hljs-comment">; j &lt; 128; j++)</span><br>                arr[i][j] <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure> <figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs abnf">int arr[<span class="hljs-number">10</span>][<span class="hljs-number">128</span>]<span class="hljs-comment">;</span><br><br>for (i <span class="hljs-operator">=</span> <span class="hljs-number">0</span><span class="hljs-comment">; i &lt; 128; i++)</span><br>        for (j <span class="hljs-operator">=</span> <span class="hljs-number">0</span><span class="hljs-comment">; j &lt; 10; j++)</span><br>                arr[j][i] <span class="hljs-operator">=</span> <span class="hljs-number">1</span><span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure></li><li>假设cache line的大小是64字节</li><li>首先分析第一段代码<ul><li>cache控制器发现arr[0][0]缺失，便从主存中取出arr[0][0]到arr[0][15]（int数据类型占4个字节）。对于arr[0][1]-[15]来说就命中了。</li><li>之后到arr[0][16]时，又缺失，便又会在主存那里load出16个数据，64个字节。</li><li>这种情况得命中率还是较高的。</li></ul></li><li>分析第二段代码<ul><li>cache控制器发现arr[0][0]缺失，便从主存中取出arr[0][0]到arr[0][15]，之后读第二个数据arr[1][0]，结果发现又缺失了，依次类推。</li><li>当访问到arr[0][1]时，需要考虑cache的大小，如果大于数组arr的大小，那么经过前面的一系列缓存，arr[0][0]-arr[9][15]都被缓存下来，与第一段代码差不多的命中率。</li><li>但是如果cache的大小小于数组的大小，那么第二段代码的命中率就没有第一段高，自然要消耗更多的时间从主存中load数据。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
      <category>Cache</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>FIR &amp; IIR 滤波器</title>
    <link href="/2023/10/28/FIR%20&amp;%20IIR%20%E6%BB%A4%E6%B3%A2%E5%99%A8/"/>
    <url>/2023/10/28/FIR%20&amp;%20IIR%20%E6%BB%A4%E6%B3%A2%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://www.cnblogs.com/alifpga/p/7902759.html"class="uri">https://www.cnblogs.com/alifpga/p/7902759.html</a></li><li><a href="https://www.zhihu.com/question/323353814"class="uri">https://www.zhihu.com/question/323353814</a></li></ul></li></ul><hr /><h2 id="fir-物理意义">1. FIR 物理意义</h2><ul><li>滤波，就是输入信号频率 X(f) 和期望的频率特征函数 H(f)进行相乘；这是在频域的计算。那么在时间域，是做了一个卷积的计算。</li><li>因此FIR做的就是将各个时刻的输入和对应的权重参数相乘，并叠加之后输出。<ul><li>如下图所示，为一N点的FIR滤波器。满足$ y(n) =_{k=0}^{N-1}h(k)x(n-k)$</li></ul></li></ul><p><img src="3201119-20230718173257360-1137724047.png" /></p><ul><li>由于FIR每一时刻的输出都取决于之前有限个输入，因此是“有限冲激响应”。</li></ul><h2 id="iir-物理意义">2. IIR 物理意义</h2><ul><li>IIR 滤波器设计的基本方法<ul><li>先设计一个合适的模拟滤波器，然后利用复值映射把模拟滤波器变换成数字滤波器。</li></ul></li><li>模拟原型滤波器<ul><li>有 巴特沃斯滤波器、切比雪夫滤波器、贝塞尔滤波器、椭圆滤波器等。</li><li>之后有时间会进行更详细的学习。</li></ul></li><li>模拟滤波器到数字滤波器的变换<ul><li>主要有两种方法<ul><li>脉冲响应不变法：从时域响应出发，让数字滤波器的单位脉冲响应h(n)模仿模拟滤波器的单位冲激响应ha(t)，h(n)等于ha(t)的取样值。<br /></li><li>双线性变换法：从频率响应出发，让数字滤波器的频率响应逼近模拟滤波器的频率响应，进而求得数字滤波器得系统函数。</li></ul></li></ul></li><li>无限冲激响应的理解<ul><li>首先看IIR滤波器表达式: <span class="math display">\[y[n] = a_0x[n]+a_1x[n-1]+a_2x[n-2]+a_3x[n-3]+...+b_1y[n-1]+b_2y[n-2]+b_3y[n-3]+...\]</span><ul><li>可以看到该公式是存在一个递归关系的，本步的计算结果会作为下一步的输入，无限递归下去。</li></ul></li><li>由于IIR是由模拟滤波器变换得到的，以下面滤波器为例。<ul><li>当给输入一个电压值（给输入一个冲激信号），电容会被充电，但是当电压值取消后，电容的电荷会被逐渐放掉，但是理论上永远不会变成0，导致输入会在无限长的时间产生影响。</li></ul><img src="3201119-20230718224246063-1237397880.png" /></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>I2S协议</title>
    <link href="/2023/10/28/I2S%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/10/28/I2S%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li>NXP 《I2S bus specification》</li><li>NXP 《I2S在Kinetis上的应用 》</li><li><a href="https://www.python100.com/html/R62183SDTAU0.html"class="uri">https://www.python100.com/html/R62183SDTAU0.html</a></li><li><a href="https://blog.51cto.com/u_15459030/5225825"class="uri">https://blog.51cto.com/u_15459030/5225825</a></li></ul></li></ul><hr /><h2 id="i2s概述">1. I2S概述</h2><h3 id="为什么需要i2s">1.1 为什么需要I2S</h3><ul><li>I2S是I2C的变种，全称：InterIc-Sound.专门为传输音频数据而设计的。</li><li>I2S 相较于I2C和SPI有以下优点<ul><li>更低的延迟：由于I2S数据传输是连续的，不需要等待ACK信号的回复，I2S只需要使用WS和SCK信号进行数据的同步；响应速度更快。</li><li>更高的精度：I2C一次可以传输8位的数据，但是I2S可以传输16/24位的数据，对于高精度的音频设备，I2S能够满足要求。</li></ul></li></ul><h3 id="i2s-三条总线">1.2 I2S 三条总线</h3><ul><li><p>之前介绍I2C有两条总线:SCL/SDA。而I2S有三条总线如下。</p><ul><li>SCK(Continuous Serial Clock)：串行时钟，也称为位时钟BCLK。<ul><li>SCK的时钟频率 = 声道数 * 采样频率 * 采样位数。</li></ul></li><li>WS(Word Select)：字段（声道）选择信号，也称为帧时钟LRCK。<ul><li>其频率等于采样频率。</li><li>在<strong>I2S模式下</strong>：WS=1，表示传递的是右声道数据。WS=0，表示传递的是左声道数据。后面有介绍，其它模式不同。</li></ul></li><li>SD(Serial Data)：串行数据。</li></ul></li><li><p>控制器（Controller）产生SCK信号和WS信号，控制器可以是Transmitter也可以是Receiver，也可以是单独设计的控制模块。</p><p><img src="3201119-20230724112142940-41134477.png" /></p></li></ul><h3 id="i2s的三种操作模式">1.3 I2S的三种操作模式</h3><ul><li>图片来自TI的TLV320AIC3104的数据表，其中WCLK为LRCLK信号，BCLK为SCK信号。</li><li>无论哪种模式，串行数据都是以二进制补码进行传输的，且先传输MSB，LSB的位置取决于I2S的位宽，长会被截断，短会被补零。</li><li>根据下面的波形可以看到：I2S模式，WS=0-&gt;左，WS=1-&gt;右;而左对齐和右对齐和I2S模式规定相反。</li><li>不同的模式决定了解码方式也不同。</li><li>根据SD和WCLK情况可分为三种模式：<ul><li><p>I2S模式</p><ul><li>在WCLK下降沿之后的一个BCLK周期的上升沿采到的数据有效。</li><li>WCLK在BCLK下降沿变化，发送方在BCLK下降沿改变数据，而接收方在BCLK上升沿采样数据。</li></ul><p><img src="3201119-20230724144906940-1187645121.png" /></p></li><li><p>左对齐模式</p><ul><li>相较于I2S模式，没有延迟一个BCLK周期。</li><li>不需要关心数据的长度，只会对LSB进行处理，截取/补零；但是MSB不会有问题。</li><li>发送方在BCLK下降沿改变数据，而接收方在BCLK上升沿采样数据。</li></ul><p><img src="3201119-20230724145852016-1096610293.png" /></p></li><li><p>右对齐模式</p><ul><li>不足：接收设备需要事先知道传输数据的长度，否则可能会导致MSB被截断</li></ul><p><img src="3201119-20230724162951792-210572944.png" /></p></li></ul></li><li>对于I2S模式和左对齐模式，可以允许发送端和接收端数据长度不同，因为接收端和发送端可以进行相应的截断和补0.<ul><li>为了保证数据音频信号的正确传输，发送端和接收端最好使用相同的数据格式和长度。</li></ul></li></ul><h2 id="i2s-应用">2. I2S 应用</h2><ul><li>注意：这里只讨论I2S模式，不讨论左对齐/右对齐模式。</li><li>讨论基于DMA和中断的乒乓缓冲区方案，旨在降低用于处理音频数据流的CPU开销。</li><li>为什么需要该方案<ul><li>采样率一般会在8KHz-48KHz之间，甚至可以更高。如果使用CPU去处理每个中断，那么系统效率会非常低。</li><li>另外大部分的音频算法会累积音频流中的数据形成缓冲数据块，之后再对缓存数据块进行处理。</li></ul></li></ul><h3 id="方案概述">2.1 方案概述</h3><ul><li>具体方案结构框图如下图所示。<ul><li>其中R和L分别代表右通道/左通道。每个通道都有用于乒乓操作的两个缓冲区（红色和黑色）。<ul><li>乒乓相关知识可以看<ahref="https://www.cnblogs.com/qianbinbin/p/17482594.html">这篇博客</a>。</li></ul></li><li>我对框图的工作模式理解是<ul><li>前面介绍，缓冲区被划分为四块；我们这里看红色和黑色两部分。红色部分我们使用DMA将其传送到I2STX模块。<ul><li>根据要求假设N为缓冲区中采样数据数量，DMA传送了N个采样数据之后，DMA会向CPU发起一个中断。</li></ul></li><li>中断期间，CPU执行音频解码算法之后获得的输出数据，并将输出数据填充到缓冲区。</li><li>可以看到存在一个乒乓的工作模式：<ul><li>T1：中断：CPU计算完成，将数据送到缓冲区R_TX0。与此同时DMA在搬移R_TX1的数据。</li><li>T2：DMA搬移结束后再次触发中断，此时DMA继续搬移R_TX0中的数据。CPU完成计算，并将数据送到缓冲区R_TX1中。</li><li>依次类推，形成乒乓的工作模式。</li></ul></li></ul></li><li>注意：考虑到音频信号具有较强的实时性要求，因此，所有计算都必须在下个中断发生之前完成，否则会导致系统故障。</li></ul></li></ul><p><img src="3201119-20230724200700025-1774790489.png" /></p><h3 id="i2s-的-fifo-特性">2.2 I2S 的 FIFO 特性</h3><ul><li>I2S 的 FIFO从DMA中读数据，FIFO中的数据会交替发送到左右通道；判断依据可选择FIFO中是否存在空数据。<ul><li>如下图所示，当FIFO的空数据计数为2时，就会让DMA加载一条数据进入左通道，一条数据进入右通道。</li></ul><img src="3201119-20230724220704113-1334935146.png" /></li></ul><h3 id="dma-和中断-配置">2.3 DMA 和中断 配置</h3><ul><li>2.1节中有介绍到DMA和中断CPU处理之间的乒乓工作模式。下面会依据实例详细介绍。</li><li>下图可以看到，共有四个数据块，每个数据块有四个采样，每个采样都有四个字节。<ul><li>DMA的访问顺序是左右通道交叉，如：0x00,0x20,0x04,0x24...</li></ul></li><li>乒乓操作实现<ul><li>当DMA读取地址经过0x00,0x20...到达0x2c时，TX0内的所有数据都已经发送完毕，发起一个中断。</li><li>随后，CPU进行算法计算，并将数据填充到BLOCK0和BLOCK2中；与此同时，DMA处理BLOCK1和BLOCK3。</li><li>当DMA到达地址0x3c时，会发起另一个中断。</li><li>随后，CPU进行算法计算，并将数据填充到BLOCK1和BLOCK3中；与此同时，DMA处理BLOCK0和BLOCK2。</li></ul></li></ul><div data-align="center"><img src="3201119-20230724221806028-635573909.png" width = 60%/></div>]]></content>
    
    
    <categories>
      
      <category>串行接口通信协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>I2C协议（一）</title>
    <link href="/2023/10/28/I2C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2023/10/28/I2C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/362287272"class="uri">https://zhuanlan.zhihu.com/p/362287272</a></li><li><a href="https://zhuanlan.zhihu.com/p/282949543"class="uri">https://zhuanlan.zhihu.com/p/282949543</a></li><li><ahref="https://blog.csdn.net/zhangduang_KHKW/article/details/121953275"class="uri">https://blog.csdn.net/zhangduang_KHKW/article/details/121953275</a></li></ul></li></ul><hr /><ul><li>波形文件来自NXP的IIC user manual.</li></ul><hr /><h2 id="i2c-用来做什么">1. I2C 用来做什么？</h2><ul><li>全称：Inter-Integrated Circuit.</li><li>一个双向，两线（SCL/SDA）制总线协议；用于主控器件和外围设备器件互联通信。简化PCB布线，降低成本。</li><li>I2C是一种多主机总线，所以也提供了仲裁功能，仲裁相关内容见<ahref="https://www.cnblogs.com/qianbinbin/p/17489279.html">这篇博客</a>。</li></ul><h2 id="i2c-的5种速率模式">2. I2C 的5种速率模式</h2><ul><li>对于不同的器件使用不同的模式，一共有5种模式，具体可看<ahref="https://zhuanlan.zhihu.com/p/362287272">这篇文章</a>.</li></ul><h2 id="通信过程">3. 通信过程</h2><ul><li>（1）当总线空闲时，SDA和SCL都处于高电平状态。</li><li>（2）当主设备决定开始通讯时，需要<strong>首先发送开始信号</strong>。</li><li>（3）发送从机设备的地址（7bits）以及1bit数据传送方向（R/W）；一共8bit，一个字节大小的数据。</li><li>（4）被寻址的从机发送应答信号给主机。</li><li>（5）发送器送出一个字节的数据，接收器收到完毕返回一个应答信号给主机。（发送器和接收器根据（3）中指定的传送方向分别选择为主机/从机）。</li><li>（6）重复（5）直到通信完成后，主机发送停止信号释放总线。</li><li>注意：<strong>发送数据过程中不可以改变数据传送方向，在（3）那步指定之后就不可更改。</strong>除非重启通信。</li></ul><h2 id="i2c的基础信号">4. I2C的基础信号</h2><ul><li><p>起始、停止、应答和非应答信号。</p><ul><li>起始信号：SCL处于高电平时，SDA从高电平到低电平变化，为起始信号。</li><li>停止信号：SCL处于高电平时，SDA从低电平到高电平变化，为停止信号。</li></ul><p><img src="3201119-20230618154435605-1791635155.png" /></p><ul><li>应答信号：其出现在一个字节传输完成之后，第9个SCL时钟周期内，SDA总线的控制权从主机给到从机，SDA总线由于上拉电阻的原因为高，如果从机正确的收到了数据，那么会将SDA拉低。<ul><li>主机发现SDA被拉低之后，可以选择下一步操作（发下一字节的传输/停止传输）。</li><li>需要注意，应答信号是接收设备给发送设备的反馈信号，而并不一定是从机给主机的反馈信号。</li></ul></li></ul><p><img src="3201119-20230618155923953-611387111.png" /></p><ul><li>非应答信号：第9个SCL时钟周期，SDA保持高电平，表示非应答，主机就需要发送停止信号，结束通信。以下情况可能会出现非应答：<ul><li>主机指定的地址，I2C总线上没有对应地址的从机设备。</li><li>主机发送从机地址，希望通信时；从机正忙，没办法通信。</li><li>主机接收从机发送的数据，主机产生非应答信号，告诉从机不要再发数据了，传输结束了。</li></ul></li></ul></li><li><p>数据有效性</p><ul><li>I2C在进行数据传送时，在SCL为低电平时发送器向SDA上送1bit数据，此时SDA可以发生变化；在SCL为高电平时，接收器从SDA上采样1bit数据，SDA需要保持稳定。</li></ul></li></ul><p><img src="3201119-20230618154320356-1776344245.png" /></p><ul><li>I2C传输的一帧有9位信号，包括一个字节的传输信号和1bit的应答/非应答信号。对于第一笔主机发送从机的传输包括（地址7bits+ 传输方向1bit）+ 1bit应答信号。<ul><li>对于1字节的数据，先发送高位，再传送低位。<br /></li></ul></li><li>前面介绍的SCL和SDA高低电平判断有些混乱，这里做一下总结。<ul><li>在开始和结束的判断，需要判断SCL信号为高电平时，SDA的变化。</li><li>在采样SDA时，需要判断SCL信号是否为高电平/低电平采样。</li><li>在判断应答/非应答，需要在SCL为高电平时，判断SDA信号是否被拉高/拉低。</li></ul></li></ul><hr /><p>如有问题，请指正！！</p>]]></content>
    
    
    <categories>
      
      <category>串行接口通信协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>I2C协议（二）</title>
    <link href="/2023/10/28/I2C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <url>/2023/10/28/I2C%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><ahref="https://blog.csdn.net/zhangduang_KHKW/article/details/121953275"class="uri">https://blog.csdn.net/zhangduang_KHKW/article/details/121953275</a></li><li><a href="https://blog.csdn.net/u010027547/article/details/47779975"class="uri">https://blog.csdn.net/u010027547/article/details/47779975</a></li><li><a href="https://blog.csdn.net/NeoZng/article/details/128486366"class="uri">https://blog.csdn.net/NeoZng/article/details/128486366</a></li><li><a href="https://www.cnblogs.com/DoreenLiu/p/14297191.html"class="uri">https://www.cnblogs.com/DoreenLiu/p/14297191.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/388835566?utm_id=0"class="uri">https://zhuanlan.zhihu.com/p/388835566?utm_id=0</a></li></ul></li></ul><hr /><h2 id="仲裁机制">1. 仲裁机制</h2><ul><li>I2C是一个多主机的通信协议，那么就会出现多个主机都申请SDA总线权限发送开始信号和从机地址的情况，这就需要仲裁机制。</li></ul><h3 id="scl的同步">1.1 SCL的同步</h3><ul><li>这里以两个主机为例，可以拓展到多个主机上。目的：多个主机产生一个可公用的时钟。</li><li>两个主机的时钟频率不同，相位不同，使用时钟同步机制如下图所示：<ul><li>总线空闲时，SCL被上拉电阻拉高，当开始通信时，CLK1首先变成低电平，SCL也变成低电平，CLK2看到SCL拉低，便自己也拉低，并开始<strong>计数</strong>到CLK2虚线（原本应该拉低的位置）。</li><li>CLK2的低电平时间比CLK1要长，所以CLK1从拉高开始<strong>计数</strong>到CLK2和CLK1同时拉高（此时SCL也被拉高）的位置。</li><li>至此，CLK1获得了需要延长的低电平时间，CLK2获得了需要减短的高电平时间，都是通过前面计数得到的。CLK1和CLK2可以根据计数值进行调整，完成时钟的同步。</li></ul></li></ul><p><img src="3201119-20230618163225074-2122545585.png" /></p><h3 id="时钟扩展">1.2 时钟扩展</h3><ul><li>目的：I2C可以动态的调整总线的通信速率。</li><li>时钟扩展是从机发起的。<ul><li><ahref="https://www.cnblogs.com/qianbinbin/p/17488308.html">这篇博客</a>介绍了非应答信号，即从机正忙，没办法通信。SCL是正常由主机控制，在SCL为高电平时，主机采到第9个SCL周期，SDA为高，此时为非应答；主机就会发起停止信号，结束通信。</li><li>现在想要即使出现非应答也可以等待从机忙完之后可以继续传输的情况，可以对SCL信号做处理，如下。</li></ul></li><li>时钟扩展在基于上面描述，增加了从机可以控制SCL信号的硬件电路，从机在第9个SCL周期将SCL拉低，由于正忙，没办法接收处理传输的数据；主机检测到SCL被拉低，便会进入等待状态。等待从机忙完可以处理时，将SCL释放（I2C两条总线都接了上拉电阻，默认是高电平）并返回主机ACK信号，主机可以进行下一步的操作。</li></ul><h3 id="sda仲裁">1.3 SDA仲裁</h3><ul><li><strong>"线与逻辑"</strong>，在SCL为高电平时，SDA的数据等于各个主机的数据相与；每个主机将自己的数据和SDA上的数据进行比对，如果不一致，便知道失去了仲裁，就不再向SDA写数据。</li><li>如果两个主机都是向相同地址从机发起通信，那么仲裁继续，直到后续的数据位决定总线的归属权。</li><li>这种仲裁方式并不会破坏数据的有效性，因为总是有主机可以进行通信，且数据不会被改变。但这种仲裁方式无法提前设定主机的优先级。</li></ul><p><img src="3201119-20230618163641198-821963823.png" /></p><h2 id="读写时序">2. 读写时序</h2><ul><li>相同传送方向，不需要每次传输主机都发送开始信号。</li></ul><p><img src="3201119-20230618183803454-485534870.png" /></p><ul><li><p>主机写给从机</p><ul><li>其中器件地址为slave地址信息，而字地址为读/写从机内部存储单元的地址信息。</li></ul><p><img src="3201119-20230903220933713-114181872.png" /></p></li><li><p>主机读从机数据</p><ul><li><p>当前地址读</p><ul><li>I2C在读写操作之后，内部的地址指针自动加1，因此当前地址读不需要再次发送从机内部存储单元地址信息了。</li></ul><p><img src="3201119-20230903221220802-876809426.png" /></p></li><li><p>随机地址读</p><ul><li>如下图所示，需要先StartBit、发送slave地址，并设置传输为写方向；之后发送内部寄存器地址。这个过程称为DummyWrite.</li><li>之后再次重新发送StartBit、slave地址，并设置传输为读方向。从机应答，从机发送8bit数据。</li><li>为什么需要<strong>DummyWrite</strong>？因为是随机读，我们需要让从机存储单元的地址指针指向随机读取的地址，所以可以先进行DummyWrite，让存储单元的地址指针指向随机读的地址，等待从机应答后，就可以读取数据了。</li></ul></li></ul><p><img src="3201119-20230903213717676-1981068318.png" /></p></li><li><p>主机读后写/写后读</p><ul><li>传输过程中，改变传送方向，不需要主机发送停止信号释放总线，只需要重新发送开始信号就可以。</li></ul></li></ul><p><img src="3201119-20230618184525407-257373124.png" /></p>]]></content>
    
    
    <categories>
      
      <category>串行接口通信协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>串行接口通信协议-概述</title>
    <link href="/2023/10/28/%E4%B8%B2%E8%A1%8C%E6%8E%A5%E5%8F%A3%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE-%E6%A6%82%E8%BF%B0/"/>
    <url>/2023/10/28/%E4%B8%B2%E8%A1%8C%E6%8E%A5%E5%8F%A3%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE-%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://blog.csdn.net/Rocher_22/article/details/116590629"class="uri">https://blog.csdn.net/Rocher_22/article/details/116590629</a></li></ul></li></ul><hr /><h2 id="串行通信-并行通信">1. 串行通信 &amp; 并行通信</h2><ul><li>串行通信：利用一条传输线将数据位一位一位的传送。</li><li>并行通信：利用多条传输线将一个数据的多bit同时传送。</li><li>串行和并行哪个更快？<ul><li>在时钟频率较低时，因为并行可以同时传输多个bit，所以速率比串行要快。</li><li>时钟频率提高到一定程度时，由于并行通信存在很多平行且紧密的导线，信号变化越来越快，导致导线之间的干扰越来越严重。</li><li>串行通信导线少，且有差分信号加持，抗干扰能力更强，可以通过不断提升时钟频率来获得更高的传输速率，所以很多高速传输也使用串行通信，如USB、PCIe等。</li></ul></li></ul><h2 id="单工-半双工-全双工">2. 单工 &amp; 半双工 &amp; 全双工</h2><ul><li>串行通信按照传输的方向分类，有以下三种：<ul><li>单工：数据传输只能在一个固定方向上传输，这个方向固定后就不可更改，不能实现双向通信。</li><li>半双工：传输方向可以切换，但是在某个时刻，只允许数据在一个方向上传输。（如IIC通信）</li><li>全双工：允许数据同时两个方向传输，可以认为发送和接收是完全独立的。（如SPI通信）</li></ul></li></ul><h2 id="同步通信和异步通信">3.同步通信和异步通信</h2><ul><li>串行通信按照传输的方式分类，有以下两种：<ul><li>同步<ul><li>收发双方使用一根时钟信号，来进行双方数据同步，一般双方会规定在时钟上升/下降沿对数据进行采样。</li><li>SPI，IIC</li></ul></li><li>异步<ul><li>不使用时钟信号进行数据同步，而是<strong>在数据信号中穿插一些用于同步的信号位</strong>，或者以数据帧的格式传输数据，例如规定起始位、数据位、奇偶校验位、停止位等。</li><li>一些通讯还需要使用波特率衡量数据传送速率，以便更好的同步。</li><li>UART，但是USART可以同步&amp;异步通信。</li></ul></li><li>两者比较<ul><li>对于同步来说，传输内容大部分就是有效数据；而异步，传输内容会包含帧的各种标识符；所以同步通讯的效率更高。</li><li>但是同步对发送和接收方的时钟允许误差要求较小。</li></ul></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>串行接口通信协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MIPI-CSI</title>
    <link href="/2023/10/28/MIPI-CSI/"/>
    <url>/2023/10/28/MIPI-CSI/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><ahref="https://blog.csdn.net/sinat_43629962/article/details/123089993"class="uri">https://blog.csdn.net/sinat_43629962/article/details/123089993</a></li><li><a href="https://zhuanlan.zhihu.com/p/599531271"class="uri">https://zhuanlan.zhihu.com/p/599531271</a></li><li><a href="https://www.mipi.org/"class="uri">https://www.mipi.org/</a></li></ul></li></ul><hr /><h2 id="csicamera-serial-interface">1. CSI（Camera SerialInterface）</h2><ul><li>观察下图，可以看到CSI是<strong>单向差分</strong>串行接口，传输数据和时钟信号。CCI(CameraControlInterface)是<strong>双线、双向、半双工的串行接口</strong>。数据传输协议符合I2C标准。I2C相关知识见<ahref="https://www.cnblogs.com/qianbinbin/p/17488308.html">这篇博客</a>。</li></ul><div data-align="center"><img src="3201119-20230903112723912-1950951905.png" width = 50%/></div><ul><li>CSI-2 layer Definitions<ul><li>如下图所示，CSI-2可以分为5层，分别为：应用层、组包/解包层，底层协议层（LowLevel Protocol）、通道管理层和物理层。下面对每一层进行解释。</li><li>PHY Layer：物理层<ul><li>该层定义了传输介质，输入/输出电路和时钟的机制，以便可以正确的从bitstream中捕获正确的0/1.</li><li>记录传输介质的电气参数特性以及数据和时钟之间的时序关系，记录了传输的起始位(SoT)和终止位(EoT)。</li></ul></li><li>Protocal Layer：协议层<ul><li>Pixel2Byte/Byte2Pixel Packing/Unpacking Layer：像素/字节转换层。<ul><li>Transmitter在将从Application接收到的数据发送前需要将像素数据转换为对应的字节流。Receiver在将数据提供给Application之前，需要将字节流数据转换为像素数据。</li></ul></li><li>Low Level Protocol(LLP)：底层协议层<ul><li>指的是SoT与EoT之间的数据包字节流协议，最小单元是字节。</li></ul></li><li>Lane Management：Lane管理层<ul><li>Lane是指一对差分数据对，在上面Figure1中，有N对差分数据，所以有N个Lane。</li><li>在Transimitter端，需要把上层打包好的数据按顺序依次Distribute到不同的lane上。</li><li>而在Reciever端需要从不同的lane上依次接收数据并把其按顺序Merge起来。</li></ul></li><li>总结<ul><li>在Transmitter端，从Apllication层接收到的数据，被打包成字节流数据包，可以选择将错误检查信息附加在要发送的数据流上，在底层协议层进行传输，并在LaneManagement层进行分发到不同的Lane上。</li><li>在Reciever端，从PHY层接收到数据后，经过LaneManagement层进行按序Merge，在底层协议层传输时，可以将Transmitter附加的信息剥离下来，并通过相对应的逻辑进行解释，检查数据发送的完整性和正确性。</li></ul></li></ul></li><li>Application layer<ul><li>该层主要用于不同场景对数据进行处理的过程，对于Transimitter，一般为Camera生成数据包；对于Reciever，多为SOC对数据进行处理。</li></ul></li></ul></li></ul><div data-align="center"><img src="3201119-20230903115043490-1797678616.png" width = 50%/></div><h2 id="ccicamera-control-interface">2. CCI（Camera ControlInterface）</h2><h3 id="cci-主从机定义">2.1 CCI 主从机定义</h3><ul><li>I2C支持多主机多从机传输，但CCI只支持一个主机的传输。</li><li>CCI将CSI的Transmitter配置为Slave，而将Reciever配置为Master。</li></ul><h3 id="cci-message-types">2.2 CCI Message Types</h3><ul><li>CCI传输信息类型包括：Start信号、ACK信号、Stop信号以及从机地址、从机内部寄存器子地址。<ul><li>CCI的从机地址位为7bit，8bit DATA传输，以及8bit/16bitINDEX传输。</li></ul></li></ul><div data-align="center"><img src="3201119-20230903161249778-1539658959.png" width = 50%/></div><h3 id="读写操作">2.3 读写操作</h3><ul><li><p>CCI支持四种读操作和两种写操作，下面展开介绍。</p></li><li><p>（1）随机位置单次读</p><ul><li>如下图所示，主机先会发起一个虚拟的写操作，指定好从机地址以及INDEX值后，再发起读操作。至于为什么需要DummyWrite可以看<ahref="https://www.cnblogs.com/qianbinbin/p/17489279.html">这篇博客</a>。</li><li>和I2C一样，更改数据传输方向需要再次发起开始信号Sr，并且主机需要再次给从机的地址，但不需要给INDEX值。</li><li>完成一次数据读操作之后，将SDA信号拉高表示主机不应答，结束传输。</li></ul><div data-align="center"><img src="3201119-20230903163440137-201009953.png" width = 50%/></div></li><li><p>（2）随机位置连续读</p><div data-align="center"><img src="3201119-20230903224825560-1446970425.png" width = 50%/></div></li><li><p>（3）当前位置单次读</p><ul><li>使用的是Previous_index + 1，不需要Dummy Write。</li></ul><div data-align="center"><img src="3201119-20230903223348145-837229902.png" width = 50%/></div></li><li><p>（4）当前位置连续读</p><div data-align="center"><img src="3201119-20230903224946740-1858592558.png" width = 50%/></div></li><li><p>（5）随机位置单次写</p><div data-align="center"><img src="3201119-20230903225103926-1703203642.png" width = 50%/></div></li><li><p>（6）随机位置连续写</p><ul><li>下图中，我认为最后一个Data对应的Index值应为M+L-1。</li></ul><div data-align="center"><img src="3201119-20230903225324858-1566777564.png" width = 50%/></div></li></ul><h3 id="cci-multi-byte-registers">2.4 CCI Multi-Byte Registers</h3><ul><li>CSI-2 协议支持以下寄存器宽度<ul><li>8-bits - 常用寄存器宽度</li><li>16bits - parameters like line-length, frame-length and exposurevalues（曝光值）</li><li>32bits - 用于高精度的寄存器宽度</li><li>64bits - for needs of future sensors</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>MIPI 接口协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MIPI-概述</title>
    <link href="/2023/10/28/MIPI-%E6%A6%82%E8%BF%B0/"/>
    <url>/2023/10/28/MIPI-%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/92682047"class="uri">https://zhuanlan.zhihu.com/p/92682047</a></li></ul></li></ul><hr /><h2 id="关于-mipi">1. 关于 MIPI</h2><ul><li>MIPI：Mobile Industry ProcessorInterface，MIPI联盟发起的为移动应用处理器部分接口制定的开放标准。</li><li>MIPI 包含了一套协议和标准，MIPIalliance官网可以看到下面几种应用场景，都有相对应的协议。</li></ul><div data-align="center"><img src="3201119-20230902162549960-1373239895.png" width = 60%/></div><ul><li>以 Mobile System 为例，如下图。</li></ul><div data-align="center"><img src="3201119-20230902163024179-34270586.png" width = 40%/></div><h2 id="mipi-multimedia">2. MIPI Multimedia</h2><ul><li>下图为MIPIMultimedia涉及到的协议。分为三层：应用层、协议层和物理层。</li></ul><div data-align="center"><img src="3201119-20230902171954203-567302188.png" width = 50%/></div>]]></content>
    
    
    <categories>
      
      <category>MIPI 接口协议</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>硬件预取</title>
    <link href="/2023/10/28/%E7%A1%AC%E4%BB%B6%E9%A2%84%E5%8F%96/"/>
    <url>/2023/10/28/%E7%A1%AC%E4%BB%B6%E9%A2%84%E5%8F%96/</url>
    
    <content type="html"><![CDATA[<ul><li>参考<ul><li><a href="https://zhuanlan.zhihu.com/p/373038275"class="uri">https://zhuanlan.zhihu.com/p/373038275</a></li><li>《A Primer on Hardware Prefetching》</li><li><a href="http://home.ustc.edu.cn/~shaojiemike/posts/cache/"class="uri">http://home.ustc.edu.cn/~shaojiemike/posts/cache/</a></li><li><ahref="http://staff.ustc.edu.cn/~xhzhou/CA-Spring2020/chapter04-03.pdf"class="uri">http://staff.ustc.edu.cn/~xhzhou/CA-Spring2020/chapter04-03.pdf</a></li></ul></li></ul><hr /><h2 id="预取相关">1. 预取相关</h2><h3 id="为什么需要预取">1.1 为什么需要预取</h3><ul><li>Cache的设计可以一定程度上弥补CPU和内存之间的速度差距。</li><li>多级Cache的设计与两种类型的内存访问局限性相关，分别为：时间局域性和空间局域性。但局域性原理依赖于两个基本前提：<ul><li>（1）缓存的大小适合所有的工作负载和访问模式。<ul><li>但，工作负载的容量需求变化是高度动态的，不同工作负载下所适合的缓存层次和容量与速度之间的权衡各不同。</li></ul></li><li>（2）分配和替换缓存项的策略适用于所有工作负载和访问模式。<ul><li>但，内存访问模式也是高度动态的，所以很难说某个分配策略可以在所有情况下都表现良好。</li></ul></li></ul></li><li>考虑到上面的内容，Cache虽然可以一定程度上提升性能，但仍还需要其它的优化算法。</li></ul><h3 id="预取算法">1.2 预取算法</h3><ul><li>预取算法，是一种利用存储器的空闲带宽，提前预测取数据来隐藏内存访问延迟的方法。<ul><li>通过预测后续的内存访问，并提前完成该访问，（访问可能与CPU的其它不需要内存访问的操作并行进行），隐藏内存访问延时。</li><li>假设理想情况，预测都命中了，那么内存访问几乎不会造成任何延时开销；但实际上，预测并不总是及时/正确的。</li></ul></li><li>预测机制需要考虑以下因素<ul><li>内存访问的地址的预测</li><li>预测何时发出预取<ul><li>如果太早，会在暂存位置（这里假设是cache）保持一段时间，期间可能会挤走有用的cacheline，也可能会被其它挤走。</li><li>如果太晚，没有实现隐藏内存访问延迟的功能。</li></ul></li><li>选择合适的暂存 预取数据/地址 的位置</li></ul></li><li>预取实现方式<ul><li>硬件</li><li>软件</li><li>编译器</li></ul></li><li>评估指标<ul><li>覆盖率（coverage）<ul><li>预取命中占总访存比例。</li></ul></li><li>准确度（accuracy）<ul><li>所有预取中有效预取的占比。</li></ul></li></ul></li></ul><h3 id="预取值-暂存位置">1.3 预取值 暂存位置</h3><ul><li>根据预取值的暂存位置，可以分为绑定预取和非绑定预取。</li><li>绑定预取(binding prefetch)<ul><li>预取值直接加载到处理器的寄存器中。</li><li>在发起预取之后，寄存器的值将会被绑定。</li><li>缺点<ul><li>消耗了宝贵的寄存器资源。</li><li>在预取地址错误时，可能会导致程序语义错误。<br /></li></ul></li></ul></li><li>非绑定预取(non-binding prefetch)<ul><li>将预取值放入cache中，或是用于增强cache层次的补充缓冲区(supplementalbuffer)。</li><li>对于多核，预取值所在的cache或是buffer也需要满足cachecoherence，因此该部分地址空间的信息可能也会改变。</li><li>目前大部分处理器使用的都是非绑定预取策略。</li></ul></li></ul><h2 id="地址预测">2. 地址预测</h2><ul><li>如果没有准确的预测到地址，可能导致污染cache（将有效的cacheline内容挤出），以及消耗了额外的通信量和争用资源。</li><li>数据的地址预测<ul><li>主要考虑是对 独立变量还是数据结构元素或是其它数据类型的访问，以及数据在程序中执行的操作。<ul><li>举例：按顺序读取数组的每一个元素等，这种数据结构和操作方式很好预测。</li><li>举例：对变量交错访问/多个数据结构之间的遍历访问等，这种预测较为复杂。</li></ul></li></ul></li><li>指令的地址预测<ul><li>主要考虑程序是 顺序执行 还是 执行分支（一些跳转指令）。</li></ul></li><li>Cache 层级对地址预测的影响<ul><li>在最高层，处理器和L1 Cache的接口包含了所有可以用来预测内存引用的信息，基于这些信息可以实现高精度的预取。</li><li>在较低的层级中，关于预测内存引用的信息会被过滤。例如高层cache命中后，相关的信息就不会传到低层cache，只能观察到来自高层缺失的信息。</li><li>因此地址预测还与cache块的放置策略和替换策略相关。</li></ul></li></ul><p>​</p>]]></content>
    
    
    <categories>
      
      <category>计算机组成与设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
